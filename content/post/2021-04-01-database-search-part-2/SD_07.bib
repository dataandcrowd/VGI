@article{GAO20191,
title = {Computational socioeconomics},
journal = {Physics Reports},
volume = {817},
pages = {1-104},
year = {2019},
note = {Computational Socioeconomics},
issn = {0370-1573},
doi = {https://doi.org/10.1016/j.physrep.2019.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0370157319301954},
author = {Jian Gao and Yi-Cheng Zhang and Tao Zhou},
keywords = {Socio-economic systems, Complex networks, Socioeconomic status, Economic development, Data mining, Machine learning},
abstract = {Uncovering the structure of socioeconomic systems and timely estimation of socioeconomic status are significant for economic development. The understanding of socioeconomic processes provides foundations to quantify global economic development, to map regional industrial structure, and to infer individual socioeconomic status. In this review, we will make a brief manifesto about a new interdisciplinary research field named Computational Socioeconomics, followed by detailed introduction about data resources, computational tools, data-driven methods, theoretical models and novel applications at multiple resolutions, including the quantification of global economic inequality and complexity, the map of regional industrial structure and urban perception, the estimation of individual socioeconomic status and demographic, and the real-time monitoring of emergent events. This review, together with pioneering works we have highlighted, will draw increasing interdisciplinary attentions and induce a methodological shift in future socioeconomic studies.}
}
@article{BEECO201376,
title = {Integrating space, spatial tools, and spatial analysis into the human dimensions of parks and outdoor recreation},
journal = {Applied Geography},
volume = {38},
pages = {76-85},
year = {2013},
issn = {0143-6228},
doi = {https://doi.org/10.1016/j.apgeog.2012.11.013},
url = {https://www.sciencedirect.com/science/article/pii/S0143622812001397},
author = {J. Adam Beeco and Greg Brown},
keywords = {Protected areas, Parks, GPS tracking, Landscape values, Space, Time},
abstract = {The analysis of space and the use of geographic information systems (GIS) have long been important to natural resource applications. More recently, social scientists have been exploring ways to integrate spatial concepts with social science data related to natural resources for theoretical, practical, and methodological reasons. This trend is particularly evident with research in park and protected area (PPA) management and outdoor recreation. The purpose of this paper is to present an updated review of how space has been incorporated into PPA research, integrate concepts and methods, identify gaps, and propose future directions for research. Overall, this review suggests that the incorporation of spatially-related social science data is advancing the field PPA research in an effective and viable way.}
}
@article{BAKILLAH20121918,
title = {Real time query propagation strategies with Lightweight Coordination Calculus (LCC) for ad hoc networks of geospatial databases},
journal = {Journal of Network and Computer Applications},
volume = {35},
number = {6},
pages = {1918-1933},
year = {2012},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2012.07.015},
url = {https://www.sciencedirect.com/science/article/pii/S1084804512001671},
author = {Mohamed Bakillah and Mir {Abolfazl Mostafavi} and Steve H.L. Liang and Alexander Zipf},
keywords = {Semantic interoperability, Query propagation, LCC, Agent coalition, Real time, Spatial data infrastructures},
abstract = {Large volumes of geospatial data are increasingly made available through dynamic networks, such as ad hoc networks. Consequently, new adapted query propagation approaches that take into account geospatial aspects of data are needed. Different existing query propagation approaches use various criteria to select relevant sources. In addition, many approaches rely on existing semantic mappings between sources; however, in ad hoc networks, sources move autonomously and in a dynamic fashion. Our goal is rather to reduce the number of sources that must be accessed to answer a query and, therefore, to reduce the volume of semantic mappings that needs to be computed to answer the query. In this paper, we propose three real time query propagation strategies to address this issue. Those strategies reproduce the behavior of members of a social network. The strategies are designed to be part of a real time semantic interoperability framework for ad hoc networks of geospatial databases. The strategies have been formalized with the Lightweight Coordination Calculus (LCC), which support distributed interactions based on social norms and constraints. The implementation and testing of the strategies show that they complement each other to provide optimal query answers.}
}
@article{JENDRYKE201799,
title = {Putting people in the picture: Combining big location-based social media data and remote sensing imagery for enhanced contextual urban information in Shanghai},
journal = {Computers, Environment and Urban Systems},
volume = {62},
pages = {99-112},
year = {2017},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2016.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S019897151630285X},
author = {Michael Jendryke and Timo Balz and Stephen C McClure and Mingsheng Liao},
keywords = {Geography, Remote sensing, Sina Weibo, Social media, Urbanization},
abstract = {Urbanization is a set of interrelated processes; the most visible among them are changes in the built-up environment. We relate those changes to human activity as expressed by online social media messages. This approach might shed light on urban dynamics currently intractable through existing datasets and methodologies. Microwave remote sensing images are used to identify urban built-up areas and changes within those areas in an objective way, while geocoded mobile social media messages deliver valuable information about human activity and the vitality found in those areas. A time-series stack of 36 TerraSAR-X Stripmap images and roughly six million social media messages were processed, classified, and visually and quantitatively analyzed for an experiment in Shanghai. We derived four possible cases of land classification by combining the results of both sources to a single raster layer at a 400m cell size. Quantifying these cases in a 2-by-2 confusion matrix shows positive and negative matches between built-up areas and social media messages. We see that correlation of positive matches is 72%. A combination of remotely sensed and social media data is a step towards a more granular analysis of urbanization processes than is possible from either data source alone. We put people in the picture of traditional remote sensing analysis.}
}
@article{DUNKEL2015173,
title = {Visualizing the perceived environment using crowdsourced photo geodata},
journal = {Landscape and Urban Planning},
volume = {142},
pages = {173-186},
year = {2015},
note = {Special Issue: Critical Approaches to Landscape Visualization},
issn = {0169-2046},
doi = {https://doi.org/10.1016/j.landurbplan.2015.02.022},
url = {https://www.sciencedirect.com/science/article/pii/S0169204615000559},
author = {Alexander Dunkel},
keywords = {Landscape perception, Spatio-temporal tag clouds, Crowdsourcing, Photo geodata, Social media analysis},
abstract = {Assessing information on aspects of identification, perception, emotion, and social interaction with respect to the environment is of particular importance to the fields of natural resource management. Our ability to visualize this type of information has rapidly improved with the proliferation of social media sites throughout the Internet in recent years. While many methods to extract information on human behavior from crowdsourced geodata already exist, this paper focuses on visualizing landscape perception for application to the fields of landscape and urban planning. Visualization of peoples’ perceptual responses to landscape is demonstrated with crowdsourced photo geodata from Flickr, a popular photo sharing community. A basic, general method to map, visualize, and evaluate perception and perceptual values is proposed. The approach utilizes common tools for spatial knowledge discovery and builds on existing research, but is specifically designed for implementation within the context of landscape perception analysis and particularly suited as a base for further evaluation in multiple scenarios. To demonstrate the process in application, three novel types of visualizations are presented: the mapping of sightlines in Yosemite Valley, the assessment of landscape change in the area surrounding the High Line in Manhattan, and individual location analysis for Coit Tower in San Francisco. The results suggest that analyzing crowdsourced data may contribute to a more balanced assessment of the perceived landscape, which provides a basis for a better integration of public values into planning processes.}
}
@article{BIRD2014144,
title = {Statistical solutions for error and bias in global citizen science datasets},
journal = {Biological Conservation},
volume = {173},
pages = {144-154},
year = {2014},
issn = {0006-3207},
doi = {https://doi.org/10.1016/j.biocon.2013.07.037},
url = {https://www.sciencedirect.com/science/article/pii/S0006320713002693},
author = {Tomas J. Bird and Amanda E. Bates and Jonathan S. Lefcheck and Nicole A. Hill and Russell J. Thomson and Graham J. Edgar and Rick D. Stuart-Smith and Simon Wotherspoon and Martin Krkosek and Jemina F. Stuart-Smith and Gretta T. Pecl and Neville Barrett and Stewart Frusher},
keywords = {Volunteer data, Statistical analysis, Experimental design, Linear models, Additive models, Species distribution models, Biodiversity, Reef life survey},
abstract = {Networks of citizen scientists (CS) have the potential to observe biodiversity and species distributions at global scales. Yet the adoption of such datasets in conservation science may be hindered by a perception that the data are of low quality. This perception likely stems from the propensity of data generated by CS to contain greater levels of variability (e.g., measurement error) or bias (e.g., spatio-temporal clustering) in comparison to data collected by scientists or instruments. Modern analytical approaches can account for many types of error and bias typical of CS datasets. It is possible to (1) describe how pseudo-replication in sampling influences the overall variability in response data using mixed-effects modeling, (2) integrate data to explicitly model the sampling process and account for bias using a hierarchical modeling framework, and (3) examine the relative influence of many different or related explanatory factors using machine learning tools. Information from these modeling approaches can be used to predict species distributions and to estimate biodiversity. Even so, achieving the full potential from CS projects requires meta-data describing the sampling process, reference data to allow for standardization, and insightful modeling suitable to the question of interest.}
}
@article{TK2021100395,
title = {Machine learning algorithms for social media analysis: A survey},
journal = {Computer Science Review},
volume = {40},
pages = {100395},
year = {2021},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2021.100395},
url = {https://www.sciencedirect.com/science/article/pii/S1574013721000356},
author = {Balaji T.K. and Chandra Sekhara Rao Annavarapu and Annushree Bablani},
keywords = {Social Media, Machine learning, Social network analysis, Applications of social media analysis},
abstract = {Social Media (SM) are the most widespread and rapid data generation applications on the Internet increase the study of these data. However, the efficient processing of such massive data is challenging, so we require a system that learns from these data, like machine learning. Machine learning methods make the systems to learn itself. Many papers are published on SM using machine learning approaches over the past few decades. In this paper, we provide a comprehensive survey of multiple applications of SM analysis using robust machine learning algorithms. Initially, we discuss a summary of machine learning algorithms, which are used in SM analysis. After that, we provide a detailed survey of machine learning approaches to SM analysis. Furthermore, we summarize the challenges and benefits of Machine Learning usages in SM analysis. Finally, we presented open issues and consequences in SM analysis for further research.}
}
@article{OTEROSROZAS201874,
title = {Using social media photos to explore the relation between cultural ecosystem services and landscape features across five European sites},
journal = {Ecological Indicators},
volume = {94},
pages = {74-86},
year = {2018},
note = {Landscape Indicators – Monitoring of Biodiversity and Ecosystem Services at Landscape Level},
issn = {1470-160X},
doi = {https://doi.org/10.1016/j.ecolind.2017.02.009},
url = {https://www.sciencedirect.com/science/article/pii/S1470160X17300572},
author = {Elisa Oteros-Rozas and Berta Martín-López and Nora Fagerholm and Claudia Bieling and Tobias Plieninger},
keywords = {Landscape values, Non-material benefits, Photos, Social preferences, User generated content (UGC)},
abstract = {Cultural ecosystem services, such as aesthetic and recreational enjoyment, as well as sense of place and local identity, play an outstanding role in the contribution of landscapes to human well-being. Online data shared on social networks, particularly geo-tagged photos, are becoming an increasingly attractive source of information about cultural ecosystem services. Landscape photographs tell about the significance of human relationships with landscapes, human practices in landscapes and the landscape features that might possess value in terms of cultural ecosystem services. Despite all the recent advances in this emerging methodological approach, some challenges remain to be explored: (a) how to assess a broad suite of cultural ecosystem services, beyond aesthetic beauty of landscapes, (b) how to identify the landscape features that are relevant for providing cultural ecosystem services and determine trade-offs and synergies among cultural ecosystem services. To address these challenges, we have developed a methodological approach suitable for eliciting the importance of cultural ecosystem services and the landscape features underpinning their provision across five different sites in Europe (in Estonia, Greece, Spain, Sweden and Switzerland). We have performed a content analysis of 1.404 photos uploaded in Flickr and Panoramio platforms that can represent cultural ecosystem services. Four bundles of landscapes features and cultural ecosystem services showed the relation of recreation with mountain areas (terrestrial recreation) and with water bodies (aquatic recreation). Cultural heritage, social and spiritual values were particularly attached to landscapes with woodpastures and grasslands, as well as urban features and infrastructures, i.e. to more anthropogenic landscapes. A positive though weak relationship was found between landscape diversity and cultural ecosystem services diversity. Particularly wood-pastures and shrubs were more frequently portrayed in all study sites in comparison with their actual land cover. The results can be of interest both for methodological purposes in the face of an increasing trend in the use of geo-tagged photos in the ecosystem services research and for the elicitation and comparison of landscape values across European cultural landscapes.}
}
@article{ILARRI20151418,
title = {Semantic management of moving objects: A vision towards smart mobility},
journal = {Expert Systems with Applications},
volume = {42},
number = {3},
pages = {1418-1435},
year = {2015},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2014.08.057},
url = {https://www.sciencedirect.com/science/article/pii/S0957417414005399},
author = {Sergio Ilarri and Dragan Stojanovic and Cyril Ray},
keywords = {Moving objects, Semantic data management, Mobile computing, Location-based services},
abstract = {This position paper presents our vision for the semantic management of moving objects. We argue that exploiting semantic techniques in mobility data management can bring valuable benefits to many domains characterized by the mobility of users and moving objects in general, such as traffic management, urban dynamics analysis, ambient assisted living, emergency management, m-health, etc. We present the state-of-the-art in the domain of management of semantic locations and trajectories, and outline research challenges that need to be investigated to enable a full-fledged and intelligent semantic management of moving objects and location-based services that support smarter mobility. We propose a distributed framework for the semantic enrichment and management of mobility data and analyze the potential deployment and exploitation of such a framework.}
}
@article{JANSSEN2017200,
title = {Towards a new generation of agricultural system data, models and knowledge products: Information and communication technology},
journal = {Agricultural Systems},
volume = {155},
pages = {200-212},
year = {2017},
issn = {0308-521X},
doi = {https://doi.org/10.1016/j.agsy.2016.09.017},
url = {https://www.sciencedirect.com/science/article/pii/S0308521X16305637},
author = {Sander J.C. Janssen and Cheryl H. Porter and Andrew D. Moore and Ioannis N. Athanasiadis and Ian Foster and James W. Jones and John M. Antle},
keywords = {Agricultural models, ICT, Linked data, Big data, Open science, Sensing, Visualization},
abstract = {Agricultural modeling has long suffered from fragmentation in model implementation. Many models are developed, there is much redundancy, models are often poorly coupled, model component re-use is rare, and it is frequently difficult to apply models to generate real solutions for the agricultural sector. To improve this situation, we argue that an open, self-sustained, and committed community is required to co-develop agricultural models and associated data and tools as a common resource. Such a community can benefit from recent developments in information and communications technology (ICT). We examine how such developments can be leveraged to design and implement the next generation of data, models, and decision support tools for agricultural production systems. Our objective is to assess relevant technologies for their maturity, expected development, and potential to benefit the agricultural modeling community. The technologies considered encompass methods for collaborative development and for involving stakeholders and users in development in a transdisciplinary manner. Our qualitative evaluation suggests that as an overall research challenge, the interoperability of data sources, modular granular open models, reference data sets for applications and specific user requirements analysis methodologies need to be addressed to allow agricultural modeling to enter in the big data era. This will enable much higher analytical capacities and the integrated use of new data sources. Overall agricultural systems modeling needs to rapidly adopt and absorb state-of-the-art data and ICT technologies with a focus on the needs of beneficiaries and on facilitating those who develop applications of their models. This adoption requires the widespread uptake of a set of best practices as standard operating procedures.}
}
@article{PETRISOR2016110,
title = {Assessing the Fragmentation of the Green Infrastructure in Romanian Cities Using Fractal Models and Numerical Taxonomy},
journal = {Procedia Environmental Sciences},
volume = {32},
pages = {110-123},
year = {2016},
note = {ECOSMART - Environment at Crossroads: Smart Approaches for a Sustainable Development},
issn = {1878-0296},
doi = {https://doi.org/10.1016/j.proenv.2016.03.016},
url = {https://www.sciencedirect.com/science/article/pii/S1878029616001420},
author = {Alexandru-Ionuţ Petrişor and Ion C. Andronache and Liliana Elza Petrişor and Ana-Maria Ciobotaru and Daniel Peptenatu},
keywords = {urban sprawl, ecosystem services, biodiversity, homogeneity, planning, fractal dimension, lacunarity},
abstract = {As the share of urban population increases globally each year, man-dominated systems tend to sprawl over the natural ones, substituting and fragmenting them. Urban sprawl is the main cause of many environmental issues, in tight connection with pollution and loss of biodiversity. One of the main consequences is a decrease of the ecosystem services provided by the urban green infrastructure. However, the extent of urban sprawl is spatially uneven due to the spatial structure of human settlements. Among the methods used to pinpoint sprawl, fractal analyses have a good potential for analyzing fragmentation, especially if used in conjunction with statistical methods. This study aimed to assess, in an exploratory perspective, the level of fragmentation in the Romanian cities covered by the Urban Atlas data, and determine its correlation with parameters related to their demographical and physical characteristics. In addition, taxonomical analyses were used to find whether cities or specific components of the green infrastructure can be grouped. The results did not reveal a general trend, although it seems that the green infrastructure consisted of agricultural/ semi-natural/ wetland areas, forests, green areas, sports and leisure facilities and water bodies in all of them, in different shares; with respect to their distribution, the numerical taxonomy analysis indicated that they form classes matching the types of ‘nature in the city’ previously described by ecologists, despite the particular historical evolution of each city and its particular influence on urban planning. The correlation analysis revealed that the population and its density and the share of the green infrastructure within the total area are significantly correlated with most fractal parameters. Similarly, the fractal dimension of the area, computed using Interactive Quantitative Morphology, seems to correlate with most morphological parameters. However, the taxonomical analysis of cities did not find very relevant groups due to the fact that many large Romanian cities lack Urban Atlas data. The results suggest that the degree of urban fragmentation is correlated especially with the population of cities and its density, reclaiming planning measures aimed at controlling the densification processes (sprawl, gentrification, location of specific activities etc.)}
}
@article{MITCHELL2017239,
title = {An evaluation framework for earthquake-responsive land administration},
journal = {Land Use Policy},
volume = {67},
pages = {239-252},
year = {2017},
issn = {0264-8377},
doi = {https://doi.org/10.1016/j.landusepol.2017.05.020},
url = {https://www.sciencedirect.com/science/article/pii/S0264837717302405},
author = {David Mitchell and Donald Grant and Daniel Roberge and Ganesh Prasad Bhatta and Christian Caceres},
keywords = {Earthquake, Risk, Response, Recovery, Reconstruction, Land administration, Land governance, Land information, Vulnerability, Preparedness, Mitigation, Evaluation framework, Haiti, Nepal, New Zealand},
abstract = {In recent years earthquakes and their secondary hazards have claimed the largest number of lives of all large natural disasters. Some of the world’s most earthquake-prone zones are also areas of high population density. The impact is magnified by vulnerability factors including non-enforcement of building codes, knowledge gaps, urban poverty and poor governance capacity to manage and reduce earthquake risks. Poor security of land tenure and property rights increases the vulnerability of people and affects their ability to respond to natural disasters. Earthquake recovery and reconstruction provides very significant challenges for land agencies, with these challenges differing from one country to the next due to differences in the local context. Drawing on contrasting case studies in Haiti, Nepal and New Zealand this paper identifies the common post-earthquake land administration functions and challenges that may apply to many contexts. These lessons provide land agencies and other key stakeholders with a summary of the challenges an earthquake poses for land administration at different post-disaster stages. We also discuss the policy and regulatory, institutional, operational and preparedness lessons for land administration. From these lessons we propose a framework for evaluating the earthquake-responsiveness of a land administration system. This framework can be used by a land agency in an earthquake prone region, or where an earthquake has recently occurred, to assess what challenges to land administration might occur in the event of an earthquake, and the preparedness of their land administration system.}
}
@article{BROWN2015228,
title = {Is PPGIS good enough? An empirical evaluation of the quality of PPGIS crowd-sourced spatial data for conservation planning},
journal = {Land Use Policy},
volume = {43},
pages = {228-238},
year = {2015},
issn = {0264-8377},
doi = {https://doi.org/10.1016/j.landusepol.2014.11.014},
url = {https://www.sciencedirect.com/science/article/pii/S0264837714002634},
author = {Greg Brown and Delene Weber and Kelly {de Bie}},
keywords = {PPGIS, Conservation planning, Crowd-sourcing, Spatial data quality, Spatial accuracy},
abstract = {A significant barrier to the use of public participation GIS (PPGIS) and crowd-sourcing for conservation planning is uncertainty about the quality of the spatial data generated. This study examines the quality of PPGIS data for use in conservation planning. We evaluate two dimensions of spatial data quality, positional accuracy and data completeness using empirical PPGIS data from a statewide study of public lands in Victoria, Australia. Using an expert-derived spatial conservation model for Victoria as a benchmark, we quantify the performance of a crowd-sourced public in their capacity to accurately and comprehensively identify areas of high conservation importance in the PPGIS process. About 70% of PPGIS points that identified biological/conservation values were spatially coincident (position accurate) with modeled areas of high conservation importance, with greater accuracy associated with locations in existing protected areas. PPGIS data had less positional accuracy when participants identified biological values in urban areas and on non-public lands in general. The PPGIS process did not comprehensively identify all the largest, contiguous areas of high conservation importance in the state, missing about 20% of areas, primarily on small public land units in less densely populated regions of the state. Preferences for increased conservation/protection were over-represented in areas proximate to the Melbourne urban area and under-represented in more remote statewide locations. Our results indicate that if PPGIS data is to be integrated into spatial models for conservation planning, it is important to account for the spatial accuracy and completeness limitations identified in this study (i.e., urban areas, non-public lands, and smaller remote locations). The spatial accuracy and completeness of PPGIS data in this study suggests spatial data quality may be “good enough” to complement biological data in conservation planning but perhaps not good enough to overcome the mistrust associated with crowd-sourced knowledge. Recommendations to improve PPGIS data quality for prospective conservation planning applications are discussed.}
}
@incollection{2019419,
title = {Index},
editor = {Constantinos Antoniou and Loukas Dimitriou and Francisco Pereira},
booktitle = {Mobility Patterns, Big Data and Transport Analytics},
publisher = {Elsevier},
pages = {419-432},
year = {2019},
isbn = {978-0-12-812970-8},
doi = {https://doi.org/10.1016/B978-0-12-812970-8.09992-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128129708099929}
}
@article{DERISI201888,
title = {Life Cycle Cost and Return on Investment as complementary decision variables for urban flood risk management in developing countries},
journal = {International Journal of Disaster Risk Reduction},
volume = {28},
pages = {88-106},
year = {2018},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2018.02.026},
url = {https://www.sciencedirect.com/science/article/pii/S2212420918302176},
author = {Raffaele {De Risi} and Francesco {De Paola} and Jane Turpie and Timm Kroeger},
keywords = {Flood risk mitigation, Sustainable urban drainage systems, Green urban development, Cost-effectiveness, Natural infrastructure, Dar es Salaam},
abstract = {Herein we investigate Life Cycle Cost (LCC) and Return on Investment (ROI) as potential decision variables for evaluating the economic performance (ROI) and financial feasibility (LCC) of a set of flood mitigation strategies over time. The main novelty of this work is the application of LCC and ROI analyses at the urban level to an asset portfolio of flood-prone buildings. Reduced flood damage is treated probabilistically as avoided costs (LCC analysis) and returns (ROI analysis), respectively. The proposed methodology is applied to the case of Dar es Salaam, Tanzania, which suffers severe riverine flooding on a sub-annual basis. Specifically, LCC and ROI of five mitigation scenarios that include large-scale catchment rehabilitation, settlement set-backs and waste management are compared with the current situation. The main result is that the highest-performing flood mitigation option includes both conventional interventions and ecosystem rehabilitation.}
}
@article{CARDOSO2019100256,
title = {Organizing collective action: Does information and communication technology matter?},
journal = {Information and Organization},
volume = {29},
number = {3},
pages = {100256},
year = {2019},
issn = {1471-7727},
doi = {https://doi.org/10.1016/j.infoandorg.2019.100256},
url = {https://www.sciencedirect.com/science/article/pii/S1471772717302828},
author = {Ana Cardoso and Marie-Claude Boudreau and João Álvaro Carvalho},
keywords = {Organizing collective action, Information and communication technology, ICT ensembles, Mass collaboration, Consensus movements, Human agency},
abstract = {In recent years, there have been significant changes in the fields of collective action and political activism. The increasing use of ICTs in social interactions has facilitated informal ways of organizing and affected the participation, emergence, and organizing of conflictual and consensual collective actions. In this study we seek to understand how the integrated use of multiple ICTs, that is the ICT ensemble, affects the organizing of consensual collective action. We investigated the ICT ensembles used by two civic movements that successfully organized large-scale consensual collective action events in two European countries. In our results, we reveal how ICT ensembles constrained and facilitated the organizing functions and requirements of collective action. The findings show that ICTs allow organizers to operate purposefully in order to organize collective action, but the extent to which they succeed in the actual concretization of collective action actually depends on their capacities and intents. Therefore, we argue that human factors (that is, their resourcefulness and agency) are greatly implicated in the success of collective action supported by ICTs. This study extends the research on impact of technology-enabled collective action by looking at the combined use of multiple ICTs and examining the rare and overlooked phenomenon of consensual collective action.}
}
@article{ALAMDAR201668,
title = {Towards multi-agency sensor information integration for disaster management},
journal = {Computers, Environment and Urban Systems},
volume = {56},
pages = {68-85},
year = {2016},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2015.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S0198971515300351},
author = {Farzad Alamdar and Mohsen Kalantari and Abbas Rajabifard},
keywords = {Multi-agency, Disaster management, Sensor information integration, In situ sensing, OGC Sensor Web Enablement, Sensor web services},
abstract = {Having access to real-time spatial information is central to the functioning of disaster management, and in particular disaster response. Existing spatially-enabled solutions for managing urban disasters provide limited support for time-sensitivity and urgency underlying emergency situations. These approaches mainly suffer from low temporal resolution and inability to source a broad range of required disaster data, together with insufficient support for automated operations. However, disaster management procedures, integrated with in situ sensing, promise an extensive range of real-time data and automated processes to acquire and manage disaster information. In this research, we study the process of integrating multi-agency in situ sensors for supporting disaster management. For this purpose, the research was adopted in Australia as the case study area in disaster management of a flood by emphasizing on the response phase. This paper first identifies the issues and existing requirements in the process of multi-agency sensor information integration and then proposes a standard-based approach to overcoming these integration issues. Afterward, based on the presented approach and identified requirements, a GIS-based software IDDSS-Sensor is implemented to provide the functions of standard-based access, as well as on-the-fly harmonization, integration and usage of multi-agency sensor information. We evaluate the applicability of our developed approach by applying it to the use case of supporting flash flood evacuation response.}
}
@article{FRITZ2012110,
title = {Geo-Wiki: An online platform for improving global land cover},
journal = {Environmental Modelling & Software},
volume = {31},
pages = {110-123},
year = {2012},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2011.11.015},
url = {https://www.sciencedirect.com/science/article/pii/S1364815211002787},
author = {Steffen Fritz and Ian McCallum and Christian Schill and Christoph Perger and Linda See and Dmitry Schepaschenko and Marijn {van der Velde} and Florian Kraxner and Michael Obersteiner},
keywords = {Land cover validation, Crowd-sourcing, Web map services, GEOSS, SOA},
abstract = {Land cover derived from remotely sensed products is an important input to a number of different global, regional and national scale applications including resource assessments and economic land use models. During the last decade three global land cover datasets have been created, i.e. the GLC-2000, MODIS and GlobCover, but comparison studies have shown that there are large spatial discrepancies between these three products. One of the reasons for these discrepancies is the lack of sufficient in-situ data for the development of these products. To address this issue, a crowdsourcing tool called Geo-Wiki has been developed. Geo-Wiki has two main aims: to increase the amount of in-situ land cover data available for training, calibration and validation, and to create a hybrid global land cover map that provides more accurate land cover information than any current individual product. This paper outlines the components that comprise Geo-Wiki and how they are integrated in the architectural design. An overview of the main functionality of Geo-Wiki is then provided along with the current usage statistics and the lessons learned to date, in particular the need to add a mechanism for feedback and interaction as part of community building, and the need to address issues of data quality. The tool is located at geo-wiki.org.}
}
@article{YU201532,
title = {The analysis and delimitation of Central Business District using network kernel density estimation},
journal = {Journal of Transport Geography},
volume = {45},
pages = {32-47},
year = {2015},
issn = {0966-6923},
doi = {https://doi.org/10.1016/j.jtrangeo.2015.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S0966692315000721},
author = {Wenhao Yu and Tinghua Ai and Shiwei Shao},
keywords = {Central Business District, Kernel density estimation, Point of Interest, Network analysis},
abstract = {Central Business District (CBD) is the core area of urban planning and decision management. The cartographic definition and representation of CBD is of great significance in studying the urban development and its functions. In order to facilitate these processes, the Kernel Density Estimation (KDE) is a very efficient tool as it considers the decay impact of services and allows the enrichment of the information from a very simple input scatter plot to a smooth output density surface. However, most existing methods of density analysis consider geographic events in a homogeneous and isotropic space under Euclidean space representation. Considering the case that the physical movement in the urban environment is usually constrained by a street network, we propose a different method for the delimitation of CBD with network configurations. First, starting from the locations of central activities, a concentration index is presented to visualize the functional urban environment by means of a density surface, which is refined with network distances rather than Euclidean ones. Then considering the specialties of network distance computation problem, an efficient way supported by flow extension simulation is proposed. Taking Shenzhen and Guangzhou, two quite developed cities in China as two case studies, we demonstrate the easy implementation and practicability of our method in delineating CBD.}
}
@incollection{201537,
title = {Subject Index},
editor = {James D. Wright},
booktitle = {International Encyclopedia of the Social & Behavioral Sciences (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {37-923},
year = {2015},
isbn = {978-0-08-097087-5},
doi = {https://doi.org/10.1016/B978-0-08-097086-8.99039-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780080970868990391}
}
@article{SEPPANEN2015112,
title = {Shared situational awareness and information quality in disaster management},
journal = {Safety Science},
volume = {77},
pages = {112-122},
year = {2015},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2015.03.018},
url = {https://www.sciencedirect.com/science/article/pii/S0925753515000764},
author = {Hannes Seppänen and Kirsi Virrantaus},
keywords = {Critical information, Disaster management, Information quality, Shared situational awareness},
abstract = {The importance of timely and accurate information for the relevant actors in disaster response is essential. Disaster response efforts are based on relevant facts concerning the situation at hand. The relevant information alone is not sufficient if the quality of that information does not meet the needs. Quality literature focuses mainly on the producer point of view of quality or the information systems perspective of quality. There is a need for a broader approach that combines the information needs in certain contexts with different aspects of information quality. The research presented in this paper suggests a method for defining the critical information and the relevant information quality elements that is required to build the SSA in disaster response. The method can be used for improving the performance and shared situational awareness required for the response operation by finding the essential information quality needs and gaps.}
}
@article{NEWMAN201755,
title = {Leveraging the power of place in citizen science for effective conservation decision making},
journal = {Biological Conservation},
volume = {208},
pages = {55-64},
year = {2017},
note = {The role of citizen science in biological conservation},
issn = {0006-3207},
doi = {https://doi.org/10.1016/j.biocon.2016.07.019},
url = {https://www.sciencedirect.com/science/article/pii/S0006320716302841},
author = {G. Newman and M. Chandler and M. Clyde and B. McGreavy and M. Haklay and H. Ballard and S. Gray and R. Scarpino and R. Hauptfeld and D. Mellor and J. Gallo},
keywords = {Citizen science, Power of place, Place-based citizen science, Integrated citizen science, Social-ecological systems, Conservation decision making, Open science, GIS, Open data},
abstract = {Many citizen science projects are place-based - built on in-person participation and motivated by local conservation. When done thoughtfully, this approach to citizen science can transform humans and their environment. Despite such possibilities, many projects struggle to meet decision-maker needs, generate useful data to inform decisions, and improve social-ecological resilience. Here, we define leveraging the ‘power of place’ in citizen science, and posit that doing this improves conservation decision making, increases participation, and improves community resilience. First, we explore ‘place’ and identify five place dimensions: social-ecological, narrative and name-based, knowledge-based, emotional and affective, and performative. We then thematically analyze 134 case studies drawn from CitSci.org (n=39), The Stewardship Network New England (TSN-NE; n=39), and Earthwatch (n=56) regarding: (1) use of place dimensions in materials (as one indication of leveraging the power of place), (2) intent for use of data in decision-making, and (3) evidence of such use. We find that 89% of projects intend for data to be used, 46% demonstrate no evidence of use, and 54% provide some evidence of use. Moreover, projects used in decision making leverage more (t=−4.8, df=117; p<0.001) place dimensions (x̅=3.0; s=1.4) than those not used in decision making (x̅=1.8; s=1.2). Further, a Principal Components Analysis identifies three related components (aesthetic, narrative and name-based, and social-ecological). Given these findings, we present a framework for leveraging place in citizen science projects and platforms, and recommend approaches to better impart intended outcomes. We discuss place in citizen science related to relevance, participation, resilience, and scalability and conclude that effective decision making as a means towards more resilient and sustainable communities can be strengthened by leveraging the power of place in citizen science.}
}
@article{WANG202096,
title = {Optimizing and accelerating space–time Ripley ’s K function based on Apache Spark for distributed spatiotemporal point pattern analysis},
journal = {Future Generation Computer Systems},
volume = {105},
pages = {96-118},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.11.036},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19314815},
author = {Yuan Wang and Zhipeng Gui and Huayi Wu and Dehua Peng and Jinghang Wu and Zousen Cui},
keywords = {Point pattern analysis, Spatiotemporal index, Caching, Spatiotemporal data partitioning, Spatiotemporal object serialization, High-performance computing},
abstract = {With increasing point of interest (POI) datasets available with fine-grained spatial and temporal attributes, space–time Ripley’s K function has been regarded as a powerful approach to analyze spatiotemporal point process. However, space–time Ripley’s K function is computationally intensive for point-wise distance comparisons, edge correction and simulations for significance testing. Parallel computing technologies like OpenMP, MPI and CUDA have been leveraged to accelerate the K function, and related experiments have demonstrated the substantial acceleration. Nevertheless, previous works have not extended optimization of Ripley’s K function from space dimension to space–time dimension. Without sophisticated spatiotemporal query and partitioning mechanisms, extra computational overhead can be problematic. Meanwhile, these researches were limited by the restricted scalability and relative expensive programming cost of parallel frameworks and impeded their applications for large POI dataset and Ripley’s K function variations. This paper presents a distributed computing method to accelerate space–time Ripley’s K function upon state-of-the-art distributed computing framework Apache Spark, and four strategies are adopted to simplify calculation procedures and accelerate distributed computing respectively: (1) spatiotemporal index based on R-tree is utilized to retrieve potential spatiotemporally neighboring points with less distance comparison; (2) spatiotemporal edge correction weights are reused by 2-tier cache to reduce repetitive computation in L value estimation and simulations; (3) spatiotemporal partitioning using KDB-tree is adopted to decrease ghost buffer redundancy in partitions and support near-balanced distributed processing; (4) customized serialization with compact representations of spatiotemporal objects and indexes is developed to lower the cost of data transmission. Based on the optimized method, a web-based visual analytics framework prototype has been developed. Experiments prove the feasibility and time efficiency of the proposed method, and also demonstrate its value on promoting applications of space–time Ripley’s K function in ecology, geography, sociology, economics, urban transportation and other fields.}
}
@article{HAYBATOLLAHI201557,
title = {Neighbourhood preferences, active travel behaviour, and built environment: An exploratory study},
journal = {Transportation Research Part F: Traffic Psychology and Behaviour},
volume = {29},
pages = {57-69},
year = {2015},
issn = {1369-8478},
doi = {https://doi.org/10.1016/j.trf.2015.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S1369847815000078},
author = {Mohammad Haybatollahi and Michal Czepkiewicz and Tiina Laatikainen and Marketta Kyttä},
keywords = {Active travel behaviour, Built environment, Neighbourhood preferences, Neighbourhood stability, Green structure},
abstract = {In the current study we investigated the extent to which neighbourhood preferences could be used as a base to group people in order to explore their residential and travel choices. The basic idea of this study was that the preferences people would have for their residential and travel choices might be a robust predictor of their actual travel behaviour, and that the neighbourhood preferences might distinguish people in terms of the characteristics of their living environment. We used a moderation model to test whether the effect of built environment on travel behaviour varied in terms of resident’s type. A total of 3403 inhabitants of the city of Tampere in Finland participated in the study. A web-based public participation GIS survey combining the questionnaires with a map (SoftGIS technique) was used to collect the data. We identified two distinct groups of residents in terms of general neighbourhood preferences. The findings showed that clustering residents based on neighbourhood preferences moderated the association between some features of density measures and travel behaviour. We found significant differences between the two clusters in both the frequencies and the distance of pedestrian and bike travel. The findings revealed that inhabitants of neighbourhoods with a larger percentage of green surroundings had a greater perception of neighbourhood stability than did the residents of neighbourhoods with a smaller percentage of green surroundings.}
}
@article{GRANELL2016231,
title = {Beyond data collection: Objectives and methods of research using VGI and geo-social media for disaster management},
journal = {Computers, Environment and Urban Systems},
volume = {59},
pages = {231-243},
year = {2016},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2016.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0198971516300060},
author = {Carlos Granell and Frank O. Ostermann},
keywords = {VGI, Crowdsourcing, Geo-social media, data analysis methods, Disaster management, Systematic mapping},
abstract = {This paper investigates research using VGI and geo-social media in the disaster management context. Relying on the method of systematic mapping, it develops a classification schema that captures three levels of main category, focus, and intended use, and analyzes the relationships with the employed data sources and analysis methods. It focuses the scope to the pioneering field of disaster management, but the described approach and the developed classification schema are easily adaptable to different application domains or future developments. The results show that a hypothesized consolidation of research, characterized through the building of canonical bodies of knowledge and advanced application cases with refined methodology, has not yet happened. The majority of the studies investigate the challenges and potential solutions of data handling, with fewer studies focusing on socio-technological issues or advanced applications. This trend is currently showing no sign of change, highlighting that VGI research is still very much technology-driven as opposed to theory- or application-driven. From the results of the systematic mapping study, the authors formulate and discuss several research objectives for future work, which could lead to a stronger, more theory-driven treatment of the topic VGI in GIScience.}
}
@incollection{COPPOLA2020805,
title = {Chapter 11 - Special considerations},
editor = {Damon P. Coppola},
booktitle = {Introduction to International Disaster Management (Fourth Edition)},
publisher = {Butterworth-Heinemann},
edition = {Fourth Edition},
pages = {805-841},
year = {2020},
isbn = {978-0-12-817368-8},
doi = {https://doi.org/10.1016/B978-0-12-817368-8.00011-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128173688000117},
author = {Damon P. Coppola},
keywords = {Adaptation, Climate change, Compound emergencies, Coordination, Corruption, Development, Donor fatigue, Early warning, Equality in humanitarian assistance, Global disasters, Institutional capacity development, Political will, Risk reduction, State sovereignty, Terrorism, The media},
abstract = {Abstract:
International disaster management has become increasingly diverse, encompassing new areas of technical expertise not traditionally considered relevant to the practice. The incidence of disasters is increasing, and populations face growing risk. These trends continue despite efforts to counter them. Disaster management will remain a global topic of concern for many decades to come. To continue to develop the field of risk management, the international disaster management community will have to solve several ongoing issues of contention and sources of uncertainty, including coordination of responders, the role of the media, the development of institutional emergency management capacities, the political will to make risk reduction happen, the prevalence of compound emergencies that make management much more complex, the risks associated with donor fatigue, corruption, uncooperative governments, the importance of ensuring equality in humanitarian assistance and relief distribution, the effect of climate change on the incidence and severity of disasters, a need for improved early warning, a true linkage of risk reduction and development practices, and a distinction between development and reconstruction. Terrorism will continue to play a large role in focusing the agendas of government emergency management agencies. Finally, global disasters, by which all countries are affected in one way or another, will only increase in number.}
}
@incollection{LI2018313,
title = {1.22 - Spatial Data Uncertainty},
editor = {Bo Huang},
booktitle = {Comprehensive Geographic Information Systems},
publisher = {Elsevier},
address = {Oxford},
pages = {313-340},
year = {2018},
isbn = {978-0-12-804793-4},
doi = {https://doi.org/10.1016/B978-0-12-409548-9.09610-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012409548909610X},
author = {Linna Li and Hyowon Ban and Suzanne P. Wechsler and Bo Xu},
keywords = {Accuracy, Ambiguity, Big data, Data quality, Error, Fuzzy sets, MAUP, Monte Carlo simulation, Ontology, Scale, Semantic uncertainty, Uncertainty, Vagueness},
abstract = {Uncertainty is an attendant characteristic of all spatial data. Spatial data are complex, as are the phenomena and processes we use these data to represent, model, and understand. Although not exhaustive, this article reviews fundamental concepts related to spatial data uncertainty and methods the geospatial research communities have developed to understand and represent uncertainty. Addressing uncertainty is an ongoing creative exploration and challenge. Especially in the era of big geospatial data, spatial analyses and spatial datasets evolve with technological advances; therefore, new methods for studying uncertainty will be required. In the meantime, existing methods reviewed here should be more widely integrated into standard geospatial practice.}
}
@article{MILLER201351,
title = {Developing context-sensitive livability indicators for transportation planning: a measurement framework},
journal = {Journal of Transport Geography},
volume = {26},
pages = {51-64},
year = {2013},
issn = {0966-6923},
doi = {https://doi.org/10.1016/j.jtrangeo.2012.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S0966692312002189},
author = {Harvey J. Miller and Frank Witlox and Calvin P. Tribby},
keywords = {Livability, Sustainability, Indicators, Multicriteria analysis, Spatial analysis, Geodesign},
abstract = {New emphases on livability and sustainability are creating demands for measuring and applying these concepts in transportation policy and planning. However, livability and sustainability are complex, multidimensional concepts that require careful measurement if they are to be applied meaningfully in plan evaluation and benchmarking. This paper provides a framework for constructing and applying quantitative livability and sustainability indicators. In addition to critically reviewing principles of constructing indicators describing a multidimensional concept such as livability or sustainability, we also discuss methods for capturing local context, a critical feature for transportation planning. Specifically, we review methods for incorporating diverse stakeholder perspectives into indicator construction and spatial analytic tools for geographic entities and relationships. We also discuss spatial decision support systems and the Geodesign concept for organizing these tools and technologies as well as integrating livability indicators into the overall planning process.}
}
@article{ZHANG201668,
title = {Analysis of spatial patterns of public attention on housing prices in Chinese cities: A web search engine approach},
journal = {Applied Geography},
volume = {70},
pages = {68-81},
year = {2016},
issn = {0143-6228},
doi = {https://doi.org/10.1016/j.apgeog.2016.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S0143622816300315},
author = {Zuo Zhang and Wenwu Tang},
keywords = {Urban study, Housing price, Baidu Index, Spatial structure, Web search engine},
abstract = {Housing price has become one of the most pressing issues facing urban residents in China in recent years and received considerable attention. However, detailed housing price data are often ill-documented or unavailable for the public, thus posing a grand challenge for the study of housing prices in China. Because individuals' Internet search activities can be recorded by web search engines, the analysis of these web search activities in cyber-space may provide a means of better understanding public attention and associated concerns in real geographic space. In this study, we focus on exploring the spatial patterns of public attention on housing price through the analysis of web query activities based on Baidu Index, a Chinese keyword analysis tool from Baidu web search engine. We propose a new index based on keyword query outcome from Baidu search database to analyze spatially heterogeneous patterns of housing price attention from 19 large and medium-sized cities in China. We evaluate the spatial network structure of housing price attention, and develop a new index to measure the intensity of interaction relationships among cities of interest. Our results show that spatial interactions of housing price attention between cities evaluated using the new method are consistent with those from a gravity model. Meanwhile, as revealed from Baidu Index-based indicators, strong spatial association patterns exist among cities that form urban agglomerations. Further, our results demonstrate that the web search engine approach, based on the coupling of cyber-space and geographic space, provides solid support for the study of housing price attention and its spatially explicit patterns in China.}
}
@article{YANG2010264,
title = {Geospatial Cyberinfrastructure: Past, present and future},
journal = {Computers, Environment and Urban Systems},
volume = {34},
number = {4},
pages = {264-277},
year = {2010},
note = {Geospatial Cyberinfrastructure},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2010.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0198971510000268},
author = {Chaowei Yang and Robert Raskin and Michael Goodchild and Mark Gahegan},
keywords = {Cyberinfrastructure, Cloud computing, Virtual organizations, Geospatial science, Spatial computing, SDI},
abstract = {A Cyberinfrastructure (CI) is a combination of data resources, network protocols, computing platforms, and computational services that brings people, information, and computational tools together to perform science or other data-rich applications in this information-driven world. Most science domains adopt intrinsic geospatial principles (such as spatial constraints in phenomena evolution) for large amounts of geospatial data processing (such as geospatial analysis, feature relationship calculations, geospatial modeling, geovisualization, and geospatial decision support). Geospatial CI (GCI) refers to CI that utilizes geospatial principles and geospatial information to transform how research, development, and education are conducted within and across science domains (such as the environmental and Earth sciences). GCI is based on recent advancements in geographic information science, information technology, computer networks, sensor networks, Web computing, CI, and e-research/e-science. This paper reviews the research, development, education, and other efforts that have contributed to building GCI in terms of its history, objectives, architecture, supporting technologies, functions, application communities, and future research directions. Similar to how GIS transformed the procedures for geospatial sciences, GCI provides significant improvements to how the sciences that need geospatial information will advance. The evolution of GCI will produce platforms for geospatial science domains and communities to better conduct research and development and to better collect data, access data, analyze data, model and simulate phenomena, visualize data and information, and produce knowledge. To achieve these transformative objectives, collaborative research and federated developments are needed for the following reasons: (1) to address social heterogeneity to identify geospatial problems encountered by relevant sciences and applications, (2) to analyze data for information flows and processing needed to solve the identified problems, (3) to utilize Semantic Web to support building knowledge and semantics into future GCI tools, (4) to develop geospatial middleware to provide functional and intermediate services and support service evolution for stakeholders, (5) to advance citizen-based sciences to reflect the fact that cyberspace is open to the public and citizen participation will be essential, (6) to advance GCI to geospatial cloud computing to implement the transparent and opaque platforms required for addressing fundamental science questions and application problems, and (7) to develop a research and development agenda that addresses these needs with good federation and collaboration across GCI communities, such as government agencies, non-government organizations, industries, academia, and the public.}
}
@article{RECALEGARI2016223,
title = {City data dating: Emerging affinities between diverse urban datasets},
journal = {Information Systems},
volume = {57},
pages = {223-240},
year = {2016},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2015.08.001},
url = {https://www.sciencedirect.com/science/article/pii/S0306437915001362},
author = {Gloria {Re Calegari} and Irene Celino and Diego Peroni},
keywords = {Smart city, Data diversity, Spatio-temporal data resolution, Mobile data processing, Correlation analysis, Regression analysis, Clustering analysis, Information fusion},
abstract = {Cities are complex environments in which digital technologies are more and more pervasive; this digitization of the urban space has led to a rich ecosystem of data producers and data consumers. Moreover, heterogeneous sources differ in terms of data complexity, spatio-temporal resolution and curation/maintenance costs. Do those diverse urban sources reflect the same picture of the city? Do distinct perspectives share some commonalities? In this paper we present our data analytics/empirical experiments on a set of urban sources related to the city of Milano; our investigation is aimed at discovering “affinities” between datasets by means of different quantitative and qualitative correlation analyses. We also explore the influence of spatial resolution and data complexity on the dependence strength between heterogeneous urban sources, to pave the way to a meaningful information fusion.}
}
@article{MCKENZIE20151,
title = {Where is also about time: A location-distortion model to improve reverse geocoding using behavior-driven temporal semantic signatures},
journal = {Computers, Environment and Urban Systems},
volume = {54},
pages = {1-13},
year = {2015},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2015.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0198971515000563},
author = {Grant McKenzie and Krzysztof Janowicz},
keywords = {Reverse geocoding, Point of interest, Semantic signature, Geosocial check-in, Time},
abstract = {While geocoding returns coordinates for a full or partial address, the converse process of reverse geocoding maps coordinates to a set of candidate place identifiers such as addresses or toponyms. For example, numerous Web APIs map geographic point coordinates, e.g., from a user’s smartphone, to an ordered set of nearby Places Of Interest (POI). Typically, these services return the k nearest POI within a certain radius and measure distance to order the results. Reverse geocoding is a crucial task for many applications and research questions as it translates between spatial and platial views on geographic location. What makes this process difficult is the uncertainty of the queried location and of the point features used to represent places. Even if both could be determined with a high level of accuracy, it would still be unclear how to map a smartphone’s GPS fix to one of many possible places in a multi-story building or a shopping mall. In this work, we break up the dependency on space alone by introducing time as a second variable for reverse geocoding. We mine the geosocial behavior of users of online location-based social networks to extract temporal semantic signatures. In analogy to the notion of scale distortion in cartography, we present a model that uses these signatures to distort the location of POI relative to the query location and time, thereby reordering the set of potentially matching places. We demonstrate the strengths of our method by evaluating it against a purely spatial baseline by determining the Mean Reciprocal Rank and the normalized Discounted Cumulative Gain. Our method performs substantially better than said baseline.}
}
@incollection{CASTI201585,
title = {Chapter 3 - Landscape as a Cartographic Icon},
editor = {Emanuela Casti},
series = {Modern Cartography Series},
publisher = {Academic Press},
volume = {6},
pages = {85-115},
year = {2015},
booktitle = {Reflexive Cartography},
issn = {1363-0814},
doi = {https://doi.org/10.1016/B978-0-12-803509-2.00003-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128035092000033},
author = {Emanuela Casti},
keywords = {Landscape and map, Landscape and perspective, Cartography and art, David Hockney, Perspective and semiotics of vision, Renaissance cartography, Cristoforo Sorte},
abstract = {The goal of this chapter is to highlight how, before the introduction of topographic metrics, the kind of space maps referred to, and the symbolic structure geographical phenomena were supposed to reflect, corresponded to the notion of a socially constructed world. By looking at some of the maps drawn in the modern period, when studies on the representation of landscape proliferated, I will try to shed light on the relations between the two forms representing territory – landscape and map – in order to make sense of the different roles that they play in communication. I will rely on the essential functions of maps – to describe or to conceptualize – and investigate what from now could be called an iconic junction, that is, the link, identified by the categories of conjunction and disjunction, which comes to exist between landscape figuration and cartographic figuration. This chapter aims not only to reflect on abstract categories but also to illustrate the relationship between these two figurative forms, recovering their underlying metrics. This will be done with a view to understanding the nature and outcome of that connection, and with it its inner meshes, over which other forms of representation freed from topographic metrics may be tested.}
}
@article{SCHEIDER201711,
title = {Why good data analysts need to be critical synthesists. Determining the role of semantics in data analysis},
journal = {Future Generation Computer Systems},
volume = {72},
pages = {11-22},
year = {2017},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.02.046},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17303047},
author = {Simon Scheider and Frank O. Ostermann and Benjamin Adams},
keywords = {Data driven analysis, Learning, Semantic Web, e-Science, Data science},
abstract = {In this article, we critically examine the role of semantic technology in data driven analysis. We explain why learning from data is more than just analyzing data, including also a number of essential synthetic parts that suggest a revision of George Box’s model of data analysis in statistics. We review arguments from statistical learning under uncertainty, workflow reproducibility, as well as from philosophy of science, and propose an alternative, synthetic learning model that takes into account semantic conflicts, observation, biased model and data selection, as well as interpretation into background knowledge. The model highlights and clarifies the different roles that semantic technology may have in fostering reproduction and reuse of data analysis across communities of practice under the conditions of informational uncertainty. We also investigate the role of semantic technology in current analysis and workflow tools, compare it with the requirements of our model, and conclude with a roadmap of 8 challenging research problems which currently seem largely unaddressed.}
}
@article{STEHMAN2019111199,
title = {Key issues in rigorous accuracy assessment of land cover products},
journal = {Remote Sensing of Environment},
volume = {231},
pages = {111199},
year = {2019},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2019.05.018},
url = {https://www.sciencedirect.com/science/article/pii/S0034425719302111},
author = {Stephen V. Stehman and Giles M. Foody},
keywords = {Probability sampling, Remote sensing, Inference, Uncertainty, Area estimation, Error matrix},
abstract = {Accuracy assessment and land cover mapping have been inexorably linked throughout the first 50 years of publication of Remote Sensing of Environment. The earliest developers of land-cover maps recognized the importance of evaluating the quality of their maps, and the methods and reporting format of these early accuracy assessments included features that would be familiar to practitioners today. Specifically, practitioners have consistently recognized the importance of obtaining high quality reference data to which the map is compared, the need for sampling to collect these reference data, and the role of an error matrix and accuracy measures derived from the error matrix to summarize the accuracy information. Over the past half century these techniques have undergone refinements to place accuracy assessment on a more scientifically credible footing. We describe the current status of accuracy assessment that has emerged from nearly 50 years of practice and identify opportunities for future advances. The article is organized by the three major components of accuracy assessment, the sampling design, response design, and analysis, focusing on good practice methodology that contributes to a rigorous, informative, and honest assessment. The long history of research and applications underlying the current practice of accuracy assessment has advanced the field to a mature state. However, documentation of accuracy assessment methods needs to be improved to enhance reproducibility and transparency, and improved methods are required to address new challenges created by advanced technology that has expanded the capacity to map land cover extensively in space and intensively in time.}
}
@incollection{2015707,
title = {Index},
editor = {Damon P. Coppola},
booktitle = {Introduction to International Disaster Management (Third Edition)},
publisher = {Butterworth-Heinemann},
edition = {Third Edition},
address = {Boston},
pages = {707-733},
year = {2015},
isbn = {978-0-12-801477-6},
doi = {https://doi.org/10.1016/B978-0-12-801477-6.18001-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128014776180013}
}
@incollection{COPPOLA2015681,
title = {Chapter 11 - Special Considerations},
editor = {Damon P. Coppola},
booktitle = {Introduction to International Disaster Management (Third Edition)},
publisher = {Butterworth-Heinemann},
edition = {Third Edition},
address = {Boston},
pages = {681-705},
year = {2015},
isbn = {978-0-12-801477-6},
doi = {https://doi.org/10.1016/B978-0-12-801477-6.00011-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128014776000113},
author = {Damon P. Coppola},
keywords = {adaptation, climate change, compound emergencies, coordination, corruption, development, donor fatigue, early warning, equality in humanitarian assistance, global disasters, institutional capacity development, political will, risk reduction, state sovereignty, terrorism, the media},
abstract = {Chapter Summaries
International disaster management has become increasingly diverse, encompassing new areas of technical expertise not traditionally considered relevant to the practice. The incidence of disasters is increasing, and populations face growing risk. These trends continue despite efforts to counter them. Disaster management will remain a global topic of concern for many decades to come. In order to continue to develop the field of risk management, the international disaster management community will have to solve several ongoing issues of contention and sources of uncertainty, including coordination of responders, the role of the media, the development of institutional emergency management capacities, the political will to make risk reduction happen, the prevalence of compound emergencies that make management much more complex, the risks associated with donor fatigue, corruption, uncooperative governments, the importance of ensuring equality in humanitarian assistance and relief distribution, the effect of climate change on the incidence and severity of disasters, a need for improved early warning, a true linkage of risk reduction and development practices, and a distinction between development and reconstruction. Terrorism will continue to play a large role in focusing the agendas of government emergency management agencies. Finally, global disasters, where all countries are affected in one way or another, will only increase in number.}
}
@article{LI202194,
title = {Image retrieval from remote sensing big data: A survey},
journal = {Information Fusion},
volume = {67},
pages = {94-115},
year = {2021},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2020.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S1566253520303778},
author = {Yansheng Li and Jiayi Ma and Yongjun Zhang},
keywords = {Remote sensing (rs) big data, Rs image retrieval methods, Rs image retrieval applications, Evaluation datasets and performance discussion, Future research directions},
abstract = {The blooming proliferation of aeronautics and astronautics platforms, together with the ever-increasing remote sensing imaging sensors on these platforms, has led to the formation of rapidly-growing earth observation data with the characteristics of large volume, large variety, large velocity, large veracity and large value, which raises awareness about the importance of large-scale image processing, fusion and mining. Unconsciously, we have entered an era of big earth data, also called remote sensing (RS) big data. Although RS big data provides great opportunities for a broad range of applications such as disaster rescue, global security, and so forth, it inevitably poses many additional processing challenges. As one of the most fundamental and important tasks in RS big data mining, image retrieval (i.e., image information mining) from RS big data has attracted continuous research interests in the last several decades. This paper mainly works for systematically reviewing the emerging achievements for image retrieval from RS big data. And then this paper further discusses the RS image retrieval based applications including fusion-oriented RS image processing, geo-localization and disaster rescue. To facilitate the quantitative evaluation of the RS image retrieval technique, this paper gives a list of publicly open datasets and evaluation metrics, and briefly recalls the mainstream methods on two representative benchmarks of RS image retrieval. Considering the latest advances from multiple domains including computer vision, machine learning and knowledge engineering, this paper points out some promising research directions towards RS big data mining. From this survey, engineers from industry may find skills to improve their RS image retrieval systems and researchers from academia may find ideas to conduct some innovative work.}
}
@article{POPLIN2012195,
title = {Playful public participation in urban planning: A case study for online serious games},
journal = {Computers, Environment and Urban Systems},
volume = {36},
number = {3},
pages = {195-206},
year = {2012},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2011.10.003},
url = {https://www.sciencedirect.com/science/article/pii/S0198971511001116},
author = {Alenka Poplin},
keywords = {Playful public participation, Urban planning, Serious online games, Game design, Game testing},
abstract = {The aim of this paper is to study the implementation of online games to encourage public participation in urban planning. Its theoretical foundations are based on previous work in public participatory geographical information systems (PP GISs), play and games, with a special focus on serious games. Serious games aim to support learning processes in a new, more playful way. We developed the concept of playful public participation in urban planning, including playful elements such as storytelling, walking and moving, sketching, drawing, and games. A group of students designed an online serious public participatory game entitled NextCampus. The case study used in NextCampus was taken from the real-world question of a possible move of a university campus to a new location in the city of Hamburg, Germany. The development of the serious public participatory game NextCampus resulted in a physical prototype, user interface design, and a computational model of the game. The NextCampus game was tested with the help of two groups of urban planning students and presented to three external experts who provided valuable recommendations for further development. The critical comments questioned the level of complexity involved in such games. The positive comments included recognition of the potential for joy and the playfulness a game like NextCampus could evoke.}
}
@article{BROWN201677,
title = {Stakeholder analysis for marine conservation planning using public participation GIS},
journal = {Applied Geography},
volume = {67},
pages = {77-93},
year = {2016},
issn = {0143-6228},
doi = {https://doi.org/10.1016/j.apgeog.2015.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S0143622815300308},
author = {Greg Brown and Jennifer Strickland-Munro and Halina Kobryn and Susan A. Moore},
keywords = {Stakeholder analysis, Conservation, PPGIS, Marine protected areas},
abstract = {Stakeholders are presumed to represent different interests for marine and coastal areas with the potential to influence marine protected area planning and management. We implemented a public participation GIS (PPGIS) system in the remote Kimberley region of Australia to identify the spatial values and preferences for marine and coastal areas. We assessed similarities and differences in PPGIS participants (N = 578) using three operational definitions for “stakeholder” based on: (1) self-identified group, (2) self-identified future interests in the region, and (3) participant value orientation that reflects a preferred trade-off between environmental and economic outcomes. We found moderate levels of association between alternative stakeholder classifications that were logically related to general and place-specific participatory mapping behavior in the study region. We then analyzed how stakeholder classifications influence specific management preferences for proposed marine protected areas (MPAs) in the study region. Conservation-related values and preferences dominated the mapped results in all proposed marine reserves, the likely result of volunteer sampling bias by conservation stakeholder interests participating in the study. However, we suggest these results may also reflect the highly politicized process of marine conservation planning in the Kimberley where conservation efforts have recently emerged and galvanized to oppose a major offshore gas development and associated land-based infrastructure. Consistent with other participatory mapping studies, our results indicate that the chosen operational definition for stakeholder group such as group identity versus interests can influence participatory mapping outcomes, with implications for MPA designation and management. Future research is needed to better understand the strengths and limitations of participatory mapping that is framed in stakeholder perspectives, especially when sampling relies heavily on volunteer recruitment and participation methods that appear predisposed to participatory bias. In parallel, practical efforts to ensure that social research efforts such as this are included in MPA planning must remain of the highest priority for scientists and managers alike.}
}
@article{SIGALA201250,
title = {Investigating the role and impact of geovisualisation and geocollaborative portals on collaborative e-learning in tourism education},
journal = {Journal of Hospitality, Leisure, Sport & Tourism Education},
volume = {11},
number = {1},
pages = {50-66},
year = {2012},
issn = {1473-8376},
doi = {https://doi.org/10.1016/j.jhlste.2012.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S1473837612000020},
author = {Marianna Sigala},
keywords = {Geoportals, Geovisualisation, Geocollaboration, E-learning, Tourism education},
abstract = {As geodata are the lifeblood of tourism, the representation of tourism resources on maps (geovisualisation) and the wide use of web 2.0 for creating and discussing geovisualised data (geocollaboration) are heavily adopted in tourism. Consequently, managing geodata needs to be incorporated into tourism curricula and pedagogies to assist graduates with career options. Although research in geovisualisation has examined the impact of geoportals on team-working and cognitive processes, research in education has not examined the implications of geocollaboration on collaborative e-learning. After reviewing the literature, the paper develops and applies a model that exploits geoportals for designing collaborative e-learning in a tourism course. Implications and trends for tourism educators and policy makers are discussed.}
}
@article{WU201623,
title = {Examining eco-environmental changes at major recreational sites in Kenting National Park in Taiwan by integrating SPOT satellite images and NDVI},
journal = {Tourism Management},
volume = {57},
pages = {23-36},
year = {2016},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2016.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S0261517716300656},
author = {Shou-Tsung Wu and Yeong-Shyang Chen},
keywords = {Remote sensing, Ecosystem environmental change, Recreational pressure, Tourism landscape, Tourism impact, National park},
abstract = {The integration of remote sensing data and vegetation indices can enable the investigation of dynamic changes in ecological environments. This study utilized SPOT satellite images from different periods as raw materials and combined geographic information system (GIS), normalized difference vegetation index (NDVI), and related statistical analyses to examine the condition of the ecological environment at the main terrestrial attractions of Kenting National Park in Taiwan. The results showed that changes in the ecological environment at the main attractions are presented to varying degrees on spatial-temporal scales. The changes are also relevant with respect to the numbers of artificial facilities and tourists. Moreover, change analysis via RGB WFM (write function memory insertion) can create spatial layouts for management. Well-conserved natural resources for sustainable development play a key role in attracting tourists. This study's investigation of the change in the main terrestrial attractions in the ecological environment of Kenting National Park may facilitate the preservation of natural resources.}
}
@article{VUURSTAEK201750,
title = {GTFS Bus Stop Mapping to the OSM Network},
journal = {Procedia Computer Science},
volume = {109},
pages = {50-58},
year = {2017},
note = {8th International Conference on Ambient Systems, Networks and Technologies, ANT-2017 and the 7th International Conference on Sustainable Energy Information Technology, SEIT 2017, 16-19 May 2017, Madeira, Portugal},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2017.05.294},
url = {https://www.sciencedirect.com/science/article/pii/S1877050917309511},
author = {Jan Vuurstaek and Glenn Cich and Luk Knapen and Ansar-Ul-Haque Yasar and Tom Bellemans and Davy Janssens},
keywords = {OpenStreetMap (OSM), General Transit Feed Specification (GTFS), Micro-Simulation, Public Transport, Mapping Algorithm},
abstract = {Abstract:
Due to budget constraints public transportation (PT) can no longer be deployed in regions where it attracts insufficient customers. Novel techniques like demand-responsive collective transportation (DRT) are evaluated to cut costs. This requires detailed simulations that are able to predict travel demand and include trip execution. Simulating facilities acting as feeder services to time-table based PT services requires detailed and accurate information about the PT infrastructure on a network. However, there are no public data sources that combine network and PT infrastructure data with the preferred level of detail. A newly developed bus stop mapping technique is presented. It uses the OpenStreetMap (OSM) and General Transit Feed Specification (GTFS) open data sources, which are maintained independently. Merging the data into a single database requires alignment. Developing bus stop mapping algorithms is challenging due to (i) inaccurate location data, (ii) inconsistent data sources and (iii) the vastly interconnected PT network and services. Due to the inaccuracy in the GTFS stop locations and in the OSM network, pure geometric considerations might lead to multiple candidate solutions to map a stop to the network. The new technique handles all GTFS trips at once and operates under the assumption that PT operators minimize the total distance driven to complete all trips.}
}
@article{EFENTAKIS2017221,
title = {Crowdsourcing turning-restrictions from map-matched trajectories},
journal = {Information Systems},
volume = {64},
pages = {221-236},
year = {2017},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2016.04.004},
url = {https://www.sciencedirect.com/science/article/pii/S0306437916301612},
author = {Alexandros Efentakis and Nikos Grivas and Dieter Pfoser and Yannis Vassiliou},
keywords = {Crowdsourcing, Turning restrictions, Map-matching, OpenStreetMaps},
abstract = {The availability of GPS-enabled devices has generated massive amounts of GPS tracking data produced by vehicles traversing the road-network. While initially used for improving traffic estimation and routing, only recently has this data been used for map-construction efforts. This work focuses on the specific aspect of identifying turning restrictions in the underlying road-network graph. We propose a novel, efficient and straightforward method to deduce turning restrictions for OpenStreetMap data, by mining historic map-matched trajectories from an existing fleet-management service. Our extensive experimental evaluation and verification process utilizing online map-services, satellite imagery, street view and public map-data APIs proves the efficiency and reliability of the proposed method.}
}
@article{YANG2018168,
title = {Generating lane-based intersection maps from crowdsourcing big trace data},
journal = {Transportation Research Part C: Emerging Technologies},
volume = {89},
pages = {168-187},
year = {2018},
issn = {0968-090X},
doi = {https://doi.org/10.1016/j.trc.2018.02.007},
url = {https://www.sciencedirect.com/science/article/pii/S0968090X18301608},
author = {Xue Yang and Luliang Tang and Le Niu and Xia Zhang and Qingquan Li},
keywords = {Road network, Lane-based intersection map, Multi-level strategies method, Crowdsourcing trace, Big data},
abstract = {Lane-based road information plays a critical role in transportation systems, a lane-based intersection map is the most important component in a detailed road map of the transportation infrastructure. Researchers have developed various algorithms to detect the spatial layout of intersections based on sensor data such as high-definition images/videos, laser point cloud data, and GPS traces, which can recognize intersections and road segments; however, most approaches do not automatically generate Lane-based Intersection Maps (LIMs). The objective of our study is to generate LIMs automatically from crowdsourced big trace data using a multi-hierarchy feature extraction strategy. The LIM automatic generation method proposed in this paper consists of the initial recognition of road intersections, intersection layout detection, and lane-based intersection map-generation. The initial recognition process identifies intersection and non-intersection areas using spatial clustering algorithms based on the similarity of angle and distance. The intersection layout is composed of exit and entry points, obtained by combining trajectory integration algorithms and turn rules at road intersections. The LIM generation step is finally derived from the intersection layout detection results and lane-based road information, based on geometric matching algorithms. The effectiveness of our proposed LIM generation method is demonstrated using crowdsourced vehicle traces. Additional comparisons and analysis are also conducted to confirm recognition results. Experiments show that the proposed method saves time and facilitates LIM refinement from crowdsourced traces more efficiently than methods based on other types of sensor data.}
}
@article{SEMANJSKI201738,
title = {Spatial context mining approach for transport mode recognition from mobile sensed big data},
journal = {Computers, Environment and Urban Systems},
volume = {66},
pages = {38-52},
year = {2017},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2017.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S0198971516304367},
author = {Ivana Semanjski and Sidharta Gautama and Rein Ahas and Frank Witlox},
keywords = {Transport mode recognition, Mobile sensed big data, Spatial awareness, Geographic information systems, Smart city, Support vector machines, Context mining, Urban data},
abstract = {Knowledge about what transport mode people use is important information of any mobility or travel behaviour research. With ubiquitous presence of smartphones, and its sensing possibilities, new opportunities to infer transport mode from movement data are appearing. In this paper we investigate the role of spatial context of human movements in inferring transport mode from mobile sensed data. For this we use data collected from more than 8000 participants over a period of four months, in combination with freely available geographical information. We develop a support vectors machines-based model to infer five transport modes and achieve success rate of 94%. The developed model is applicable across different mobile sensed data, as it is independent on the integration of additional sensors in the device itself. Furthermore, suggested approach is robust, as it strongly relies on pre-processed data, which makes it applicable for big data implementations in (smart) cities and other data-driven mobility platforms.}
}
@incollection{SCASSA2014279,
title = {Chapter 19 - Cybercartography and Traditional Knowledge: Responding to Legal and Ethical Challenges},
editor = {D.R.Fraser Taylor},
series = {Modern Cartography Series},
publisher = {Academic Press},
volume = {5},
pages = {279-295},
year = {2014},
booktitle = {Developments in the Theory and Practice of Cybercartography},
issn = {1363-0814},
doi = {https://doi.org/10.1016/B978-0-444-62713-1.00019-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780444627131000192},
author = {Teresa Scassa and Tracey P. Lauriault and D. R. Fraser Taylor},
keywords = {Ethics, Information sharing, Informed consent, Intellectual property, Law, Local and traditional knowledge (LTK), Normativity, Soft law, Traditional knowledge},
abstract = {Cybercartography offers rich potential for the mapping of traditional knowledge (TK). At the same time, the particular characteristics of TK pose significant challenges for cybercartographers. TK is more than a collection of informational ‘artefacts’ that can be placed on a map; it forms part of a knowledge system that is often fundamentally different from dominant Western systems. These differences require new paradigms for thinking about maps and their objectives generally, and for thinking more specifically about how information is represented and disseminated through cybercartography. In this chapter, the authors examine the nature of TK and the potential of cybercartography for its representation. The authors consider the role of law (defined as explicit and enforceable rules) and normativity (defined as ‘ought’ statements that guide social relations) in shaping relationships between cartographers and the contributors of TK. They consider how those involved in such projects can use both technological and legal tools to define the terms of their collaboration and to articulate their expectations in sharing their information with a global community.}
}
@incollection{PYNE201957,
title = {Chapter 3 - Mapping Jeff Thomas mapping: Exploring the reflexive relationship between art, written narrative and Cybercartography in commemorating residential schools},
editor = {Stephanie Pyne and D. R. Fraser Taylor},
series = {Modern Cartography Series},
publisher = {Academic Press},
volume = {8},
pages = {57-100},
year = {2019},
booktitle = {Cybercartography in a Reconciliation Community},
issn = {1363-0814},
doi = {https://doi.org/10.1016/B978-0-12-815343-7.00003-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780128153437000038},
author = {Stephanie Pyne and Jeff Thomas},
keywords = {Archives, Art, Cartography, Iterative processes, Reflexivity, Residential schools},
abstract = {This chapter discusses the evolution of Jeff Thomas' work in Cybercartography at the intersection of art and cartography, with a special focus on residential schools. It comments on (1) intersections between art and cartography, including reflections on how a photograph can be read like a map (2) reflexive aspects of chapter and mapping and (3) the working distinction between implicit and explicit approaches to cartography. In addition, it contributes to the expansion of the concept of ‘epi map’ (Wood and Fels, 2008) by providing an example of the knowledge generating relationship between ‘text’ and ‘map’.}
}
@article{CARBALLOCARDENAS2016114,
title = {Citizen science regarding invasive lionfish in Dutch Caribbean MPAs: Drivers and barriers to participation},
journal = {Ocean & Coastal Management},
volume = {133},
pages = {114-127},
year = {2016},
issn = {0964-5691},
doi = {https://doi.org/10.1016/j.ocecoaman.2016.09.014},
url = {https://www.sciencedirect.com/science/article/pii/S0964569116302095},
author = {Eira C. Carballo-Cárdenas and Hilde Tobi},
keywords = {Citizen science, Invasive lionfish, Marine protected areas, Motivations, Participation},
abstract = {Understanding the drivers and barriers to participation in citizen science initiatives for conservation is important if long-term involvement from volunteers is expected. This study investigates the motivations of individuals from five marine protected areas (MPAs) in the Dutch Caribbean to (not) participate in different initiatives around lionfish. Following an interpretive approach, semi-structured interviews with seventy-eight informants were conducted and analyzed using thematic network analysis. Approximately 60% (n = 48) of informants indicated that they had participated in citizen science initiatives at the outset of the invasion. From this group, almost half said that they still participated in some type of data collection, but only a few did so within a citizen science context. Many informants were initially motivated to participate in lionfish detection and response initiatives due to concern for the environment. Personal meanings attached to both the data collection experiences and to the data influenced informants’ motivations to sustain or cease data collection and/or sharing. In time, the view of lionfish as a threat changed for many informants as this species’ recreational and/or commercial value increased. Enabling and constraining factors for data collection and sharing were identified at the personal, interpersonal, organizational and technical levels. Our findings have implications for the design of future citizen science initiatives focused on invasive species.}
}
@article{KC2019101188,
title = {Cloud Computing in natural hazard modeling systems: Current research trends and future directions},
journal = {International Journal of Disaster Risk Reduction},
volume = {38},
pages = {101188},
year = {2019},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2019.101188},
url = {https://www.sciencedirect.com/science/article/pii/S2212420919302018},
author = {Ujjwal K.C. and Saurabh Garg and James Hilton and Jagannath Aryal and Nicholas Forbes-Smith},
keywords = {Natural hazard, Disaster management, Geospatial science, Cloud computing},
abstract = {Every year, natural disasters cause major loss of human life, damage to infrastructure and significant economic impact on the areas involved. Geospatial Scientists aim to help in mitigating or managing such hazards by computational modeling of these complex events, while Information Communication Technology (ICT) supports the execution of various models addressing different aspects of disaster management. The execution of natural hazard models using traditional ICT foundations is not possible in a timely manner due to the complex nature of the models, the need for large-scale computational resources as well as intensive data and concurrent-access requirements. Cloud Computing can address these challenges with near-unlimited capacity for computation, storage, and networking, and the ability, to offer natural hazard modeling systems as end services, has now become more realistic than ever. However, researchers face several open challenges in adopting and utilizing Cloud Computing technologies during disasters. As such, this survey paper aggregates all these challenges, reflects on the current research trends and outlines a conceptual Cloud-based solution framework for more effective natural hazards modeling and management systems using Cloud infrastructure in conjunction with other technologies such as Internet of Things (IoT) networks, fog, and edge computing. We draw a clear picture of the current research state in the area and suggest further research directions for future systems.}
}
@article{PICH201882,
title = {Logical composition of qualitative shapes applied to solve spatial reasoning tests},
journal = {Cognitive Systems Research},
volume = {52},
pages = {82-102},
year = {2018},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2018.06.002},
url = {https://www.sciencedirect.com/science/article/pii/S1389041717303121},
author = {Albert Pich and Zoe Falomir},
keywords = {Qualitative spatial reasoning, Qualitative shape descriptor, Shape composition, Angle composition, Length composition, Logic, Tangram, Puzzle, Spatial cognition, Spatial reasoning tests, Prolog, Logic programming},
abstract = {A logical approach to compose qualitative shape descriptors (LogC-QSD) is presented in this paper. Each object shape is described qualitatively by its edges, angles, convexities, and lengths. LogC-QSD describes the shape of composed objects qualitatively adding circuits to describe the connections among the shapes. It also infers new angles and lengths using composition tables. Its main contributions are: (i) describing qualitatively the resulting boundary of connecting N shapes and (ii) its application to solve spatial reasoning tests. LogC-QSD approach has been implemented using Prolog programming language, which is based on Horn clauses and first order logic. The testing framework was SWI-Prolog on the LogC-QSD dataset. The obtained results show that the LogC-QSD approach was able to correctly answer all the questions in the LogC-QSD dataset, which involved compositions up to five shapes. The correct answer for 60% of the questions was obtained in an average time of 2.45·10-4 s by comparing the concavities and right angles of the final QSD composed shape with the possible answers. The rest of the questions required a matching algorithm and they were solved by LogC-QSD in an average time of 19.50·10-4 s. Analysis of the execution times obtained showed that the algorithmic cost of LogC-QSD is lower than O(n2) in the worst case.}
}
@article{DELCARMENRODRIGUEZHERNANDEZ2021106740,
title = {AI-based mobile context-aware recommender systems from an information management perspective: Progress and directions},
journal = {Knowledge-Based Systems},
volume = {215},
pages = {106740},
year = {2021},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.106740},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121000034},
author = {María {del Carmen Rodríguez-Hernández} and Sergio Ilarri},
keywords = {Context-Aware Recommender Systems, Mobile computing, Context-aware computing, Personalization, Information management},
abstract = {In the Artificial Intelligence (AI) field, and particularly within the area of Machine Learning (ML), recommender systems have attracted significant research attention. These systems attempt to alleviate the increasing information overload that users can experience in the current Big Data era, by providing personalized recommendations of items that they may find relevant. Besides, given the importance of mobile computing, these systems have evolved to consider also the dynamic context of the mobile users (location, time, weather conditions, etc.) to offer them more appropriate suggestions and information while on the move. In this paper, we provide an extensive survey of recent advances towards intelligent mobile Context-Aware Recommender Systems (mobile CARS) from an information management perspective, with an emphasis on mobile computing and AI techniques, along with an analysis of existing research gaps and future research directions. We focus on approaches that go beyond just considering the location of the user and exploit also other context information. In this study, we have identified that deep learning approaches are promising artificial intelligence models for mobile CARS. Additionally, in a near future, we expect a higher prominence of push-based recommendation solutions where at least part of the recommendation engine could be executed in the mobile devices, which could share data and tasks in a distributed way.}
}
@article{VOINOV2018232,
title = {Tools and methods in participatory modeling: Selecting the right tool for the job},
journal = {Environmental Modelling & Software},
volume = {109},
pages = {232-255},
year = {2018},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2018.08.028},
url = {https://www.sciencedirect.com/science/article/pii/S1364815218303098},
author = {Alexey Voinov and Karen Jenni and Steven Gray and Nagesh Kolagani and Pierre D. Glynn and Pierre Bommel and Christina Prell and Moira Zellner and Michael Paolisso and Rebecca Jordan and Eleanor Sterling and Laura {Schmitt Olabisi} and Philippe J. Giabbanelli and Zhanli Sun and Christophe {Le Page} and Sondoss Elsawah and Todd K. BenDor and Klaus Hubacek and Bethany K. Laursen and Antonie Jetter and Laura Basco-Carrera and Alison Singer and Laura Young and Jessica Brunacini and Alex Smajgl},
keywords = {Stakeholders, Collaborative learning, Qualitative analysis, Quantitative modeling, Participatory planning, Mental models},
abstract = {Various tools and methods are used in participatory modelling, at different stages of the process and for different purposes. The diversity of tools and methods can create challenges for stakeholders and modelers when selecting the ones most appropriate for their projects. We offer a systematic overview, assessment, and categorization of methods to assist modelers and stakeholders with their choices and decisions. Most available literature provides little justification or information on the reasons for the use of particular methods or tools in a given study. In most of the cases, it seems that the prior experience and skills of the modelers had a dominant effect on the selection of the methods used. While we have not found any real evidence of this approach being wrong, we do think that putting more thought into the method selection process and choosing the most appropriate method for the project can produce better results. Based on expert opinion and a survey of modelers engaged in participatory processes, we offer practical guidelines to improve decisions about method selection at different stages of the participatory modeling process.}
}
@article{ARCAINI2016122,
title = {User-driven geo-temporal density-based exploration of periodic and not periodic events reported in social networks},
journal = {Information Sciences},
volume = {340-341},
pages = {122-143},
year = {2016},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2016.01.014},
url = {https://www.sciencedirect.com/science/article/pii/S0020025516000165},
author = {Paolo Arcaini and Gloria Bordogna and Dino Ienco and Simone Sterlacchini},
keywords = {Crawling social networks, User Query, Density-based Clustering, Geo-temporal proximity measure},
abstract = {In this paper we propose a procedure consisting of a first collection phase of social network messages, a subsequent user query selection, and finally a clustering phase, defined by extending the density-based DBSCAN algorithm, for performing a geographic and temporal exploration of a collection of items, in order to reveal and map their latent spatio-temporal structure. Specifically, both several geo-temporal distance measures and a density-based geo-temporal clustering algorithm are proposed. The approach can be applied to social messages containing an explicit geographic and temporal location. The algorithm usage is exemplified to identify geographic regions where many geotagged Twitter messages about an event of interest have been created, possibly in the same time period in the case of non-periodic events (aperiodic events), or at regular timestamps in the case of periodic events. This allows discovering the spatio-temporal periodic and aperiodic characteristics of events occurring in specific geographic areas, and thus increasing the awareness of decision makers who are in charge of territorial planning. Several case studies are used to illustrate the proposed procedure.}
}
@article{DAS2020102043,
title = {Spatio-Fog: A green and timeliness-oriented fog computing model for geospatial query resolution},
journal = {Simulation Modelling Practice and Theory},
volume = {100},
pages = {102043},
year = {2020},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2019.102043},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X19301741},
author = {Jaydeep Das and Anwesha Mukherjee and Soumya K. Ghosh and Rajkumar Buyya},
keywords = {Geospatial query, Fog computing, Cloud computing, Delay-sensitive, Power-efficient},
abstract = {Geospatial data analysis is an emerging area of research today. Systems need to respond to user requests in a timely manner. In this paper we have proposed a fog computing framework namely Spatio-Fog, where the fog devices contain the geospatial data of their current region and process geospatial queries using resources in the proximity. The geospatial query resolution is performed by the fog device either itself or using cloud servers or fog device of other region depending on the geographical region related to the geospatial query. We have performed both empirical study and experimental analysis to demonstrate feasibility of our proposed approach. The empirical study illustrates that the proposed architecture Spatio-Fog reduces the power consumption and delay by approximately 43–47% and 47–83% respectively over the use of existing geospatial query resolution system. The experimental analysis demonstrates that the proposed framework reduces the power consumption and delay by 30–60% approximately than the existing geospatial query resolution system.}
}
@article{FITZHUGH2016137,
title = {Spatio-temporal filtering techniques for the detection of disaster-related communication},
journal = {Social Science Research},
volume = {59},
pages = {137-154},
year = {2016},
note = {Special issue on Big Data in the Social Sciences},
issn = {0049-089X},
doi = {https://doi.org/10.1016/j.ssresearch.2016.04.023},
url = {https://www.sciencedirect.com/science/article/pii/S0049089X1630237X},
author = {Sean M. Fitzhugh and C. {Ben Gibson} and Emma S. Spiro and Carter T. Butts},
keywords = {Disasters, Rumoring, Communication, Geography, Event detection, Big data},
abstract = {Individuals predominantly exchange information with one another through informal, interpersonal channels. During disasters and other disrupted settings, information spread through informal channels regularly outpaces official information provided by public officials and the press. Social scientists have long examined this kind of informal communication in the rumoring literature, but studying rumoring in disrupted settings has posed numerous methodological challenges. Measuring features of informal communication–timing, content, location–with any degree of precision has historically been extremely challenging in small studies and infeasible at large scales. We address this challenge by using online, informal communication from a popular microblogging website and for which we have precise spatial and temporal metadata. While the online environment provides a new means for observing rumoring, the abundance of data poses challenges for parsing hazard-related rumoring from countless other topics in numerous streams of communication. Rumoring about disaster events is typically temporally and spatially constrained to places where that event is salient. Accordingly, we use spatio and temporal subsampling to increase the resolution of our detection techniques. By filtering out data from known sources of error (per rumor theories), we greatly enhance the signal of disaster-related rumoring activity. We use these spatio-temporal filtering techniques to detect rumoring during a variety of disaster events, from high-casualty events in major population centers to minimally destructive events in remote areas. We consistently find three phases of response: anticipatory excitation where warnings and alerts are issued ahead of an event, primary excitation in and around the impacted area, and secondary excitation which frequently brings a convergence of attention from distant locales onto locations impacted by the event. Our results demonstrate the promise of spatio-temporal filtering techniques for “tuning” measurement of hazard-related rumoring to enable observation of rumoring at scales that have long been infeasible.}
}
@article{BRUCE201483,
title = {Distribution patterns of migrating humpback whales (Megaptera novaeangliae) in Jervis Bay, Australia: A spatial analysis using geographical citizen science data},
journal = {Applied Geography},
volume = {54},
pages = {83-95},
year = {2014},
issn = {0143-6228},
doi = {https://doi.org/10.1016/j.apgeog.2014.06.014},
url = {https://www.sciencedirect.com/science/article/pii/S0143622814001301},
author = {Eleanor Bruce and Lindsey Albright and Scott Sheehan and Michelle Blewitt},
keywords = {Humpback whale, GIS, Spatial statistics, Marine management, Geographical citizen science, Jervis Bay},
abstract = {Increases in east Australian humpback whale populations, specifically in areas where sightings were previously infrequent, highlight the importance of understanding the usage patterns and habitat preferences for resting grounds along migration pathways. This study investigates the spatio-temporal distribution of humpback whales in Jervis Bay, Australia, based on pod composition, providing insight on the role of this shallow coastal embayment for mother-calf pods during the southern migration to polar feeding grounds. Geographical citizen science-based sighting data, collected from a commercial whale-watch platform during the 2007–2010 migration seasons, were used to examine variations in bay usage and pod composition. Differences in the distribution patterns of mother-calf and non-calf pod sightings were examined using spatial cluster analysis. The impact of sampling bias, introduced through non-specialist volunteer collected data, on spatial cluster detection was simulated. Observation error and spatial sampling bias may affect local spatial cluster detection. Sampling processes with potential to contribute to this bias should be recorded in the survey design of geographical citizen science based data collection programmes. Mother-calf pods showed a significant preference for the shallow waters of Jervis Bay during October and November, indicating the bay may function as a preferred resting location during their southern migration with important marine management implications.}
}
@incollection{STOCK2016171,
title = {Chapter 10 - Geospatial Reasoning With Open Data},
editor = {Robert Layton and Paul A. Watters},
booktitle = {Automating Open Source Intelligence},
publisher = {Syngress},
address = {Boston},
pages = {171-204},
year = {2016},
isbn = {978-0-12-802916-9},
doi = {https://doi.org/10.1016/B978-0-12-802916-9.00010-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128029169000105},
author = {Kristin Stock and Hans Guesgen},
keywords = {geospatial data, ontologies, spatial reasoning},
abstract = {Geospatial data is data about objects, events, or phenomena that have a location on the surface of the earth, including location information (usually coordinates on the earth), attribute information (the characteristics of the object, event, or phenomena concerned), and often also temporal information (the time or life span at which the location and attributes exist). In this chapter, we discuss the ways in which geospatial reasoning has been applied to open data. We define geospatial reasoning as both reasoning about the location of objects on the earth (e.g., relating to inference of spatial relationships) and reasoning about geospatial data (e.g., relating to the attributes of data that is geospatial in nature). We then present two case studies to illustrate the use of geospatial reasoning with open data: (1) the use of fuzzy reasoning for map buffering and (2) methods for automatically learning nonclassical ontologies from geospatial data (data driven ontologies).}
}
@article{SASAO201741,
title = {Community Reminder: Participatory contextual reminder environments for local communities},
journal = {International Journal of Human-Computer Studies},
volume = {102},
pages = {41-53},
year = {2017},
note = {Special Issue on Mobile and Situated Crowdsourcing},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2016.09.001},
url = {https://www.sciencedirect.com/science/article/pii/S1071581916301021},
author = {Tomoyo Sasao and Shin'ichi Konomi and Vassilis Kostakos and Keisuke Kuribayashi and Jorge Goncalves},
keywords = {Mobile crowdsourcing, Community, Context awareness, Reminder, Participation},
abstract = {Many projects have looked at how communities can co-design shared online repositories, such as Wikimapia and Wikipedia. However, little work has examined how local communities can give advice and support to their members by creating context-aware reminders that may include advice, tips and small requests. We developed the Community Reminder environment, a smartphone-based platform that supports community members to design and use context-aware reminders. We have conducted a one-month field study of Community Reminder to crowdsource and deliver safety-relevant information in a local community. The results show the benefits of involving community members in reminder design and connecting different perspectives. We also show that the proposed approach can broaden participation in local communities.}
}
@article{PALOMINO201779,
title = {A review of the emergent ecosystem of collaborative geospatial tools for addressing environmental challenges},
journal = {Computers, Environment and Urban Systems},
volume = {65},
pages = {79-92},
year = {2017},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2017.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0198971516304458},
author = {Jenny Palomino and Oliver C. Muellerklein and Maggi Kelly},
keywords = {Spatial Data Science, Collaboration, Tools, Multi-user, Workflows},
abstract = {To solve current environmental challenges such as biodiversity loss, climate change, and rapid conversion of natural areas due to urbanization and agricultural expansion, researchers are increasingly leveraging large, multi-scale, multi-temporal, and multi-dimensional geospatial data. In response, a rapidly expanding array of collaborative geospatial tools is being developed to help collaborators share data, code, and results. Successful navigation of these tools requires users to understand their strengths, synergies, and weaknesses. In this paper, we identify the key components of a collaborative Spatial Data Science workflow to develop a framework for evaluating the various functional aspects of collaborative geospatial tools. Using this framework, we then score thirty-one existing collaborative geospatial tools and apply a cluster analysis to create a typology of these tools. We present this typology as a map of the emergent ecosystem and functional niches of collaborative geospatial tools. We identify three primary clusters of tools composed of eight secondary clusters across which divergence is driven by required infrastructure and user involvement. Overall, our results highlight how environmental collaborations have benefitted from the use of these tools and propose key areas of future tool development for continued support of collaborative geospatial efforts.}
}
@article{LOVELACE2016277,
title = {Who, where, when: the demographic and geographic distribution of bicycle crashes in West Yorkshire},
journal = {Transportation Research Part F: Traffic Psychology and Behaviour},
volume = {41},
pages = {277-293},
year = {2016},
note = {Bicycling and bicycle safety},
issn = {1369-8478},
doi = {https://doi.org/10.1016/j.trf.2015.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S136984781500039X},
author = {Robin Lovelace and Hannah Roberts and Ian Kellar},
keywords = {Cycling, Safety, Exposure, Risk, Geographical factors},
abstract = {Factors associated with cycle safety, including international differences in injury and mortality rates, protective equipment and bicycle training, have been subject to increasing academic interest. Environmental variables associated with cycle safety have also been scrutinised, but few studies have focussed on geographical factors at the local level. This paper addresses this research gap by analysing a geo-referenced dataset of road traffic incidents, taken from the UK’s STATS19 dataset (2005–2012). We investigate incidents involving cyclists within West Yorkshire. This is an interesting case study area as it has an historically low cycling rate but very ambitions cycling plans following investment from the Department of Transport. West Yorkshire is found to be an unusually risky area for cyclists, with an estimated 53 deaths and 1372 serious injuries per billion kilometres cycled, based on census commuting statistics. This is roughly double the national average. This riskiness varies spatially and temporally, broadly in line with expectations from the previous literature. An unexpected result was that cycling seems to be disproportionately risky for young people in West Yorkshire compared with young people nationally. The case study raises the issue of potential negative health impacts of promoting cycling amongst vulnerable groups in dangerous areas. We conclude by highlighting opportunities for increasing cycling uptake via measures designed primarily to improve safety. The analysis underlying this research is reproducible, based on code stored at github.com/Robinlovelace/bikeR.}
}
@incollection{LAURIAULT2014325,
title = {Chapter 21 - The Preservation and Archiving of Geospatial Data and Cybercartography as a Proactive Preservation Process},
editor = {D.R.Fraser Taylor},
series = {Modern Cartography Series},
publisher = {Academic Press},
volume = {5},
pages = {325-342},
year = {2014},
booktitle = {Developments in the Theory and Practice of Cybercartography},
issn = {1363-0814},
doi = {https://doi.org/10.1016/B978-0-444-62713-1.00021-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780444627131000210},
author = {Tracey P. Lauriault and D. R. Fraser Taylor},
keywords = {Archives, Canada Land Inventory, Data management, Information policy, Life-cycle management, Preservation, Proactive archiving, Secondary provenance, Trusted digital repository},
abstract = {Digital mapping is now ubiquitous and an increasing amount of geodata is being created by all sectors. Despite this explosion, few data are preserved and, as a result, a fundamental source of scientific and cultural heritage, culture and knowledge, is very much at risk. The chapter therefore argues that the preservation of maps and spatial information requires dedicated resources. The authors examine the challenges and opportunities of preserving Canadian geospatial data and begin by telling the story of the rescue and salvage of the Canada Land Inventory, followed by a review of Canadian preservation initiatives, laws, policies, and directives. In addition, four existing preservation and geospatial data management examples are introduced; tools for establishing a preservation system are shown and cybercartographic atlases are discussed as traditional knowledge archives.}
}
@article{BROWN2017153,
title = {Mixed methods participatory GIS: An evaluation of the validity of qualitative and quantitative mapping methods},
journal = {Applied Geography},
volume = {79},
pages = {153-166},
year = {2017},
issn = {0143-6228},
doi = {https://doi.org/10.1016/j.apgeog.2016.12.015},
url = {https://www.sciencedirect.com/science/article/pii/S0143622816308402},
author = {Greg Brown and Jennifer Strickland-Munro and Halina Kobryn and Susan A. Moore},
keywords = {Validity, PPGIS, Marine protected areas, Participatory mapping, Australia},
abstract = {Participatory mapping in social research is characterized by methodological pluralism, with two common methods being qualitative mapping using stakeholder interviews and quantitative methods that engage larger public samples through digital, internet mapping. To date, there has been no systematic evaluation of the extent to which mixed methods in participatory mapping yield valid results when applied to the same research setting and research questions. A mixed methods research design (combined exploratory sequential and convergent parallel) was implemented in a large research project to identify marine and coastal values in the Kimberley region of Australia. Qualitative interviews (n = 167) were completed with stakeholders to identify place-based values using polygon mapping methods and internet-based public participation GIS (PPGIS) methods (n = 578). We defined and operationalized the concepts of concurrent, commensurate, and convergent validity to assess mixed methods research outcomes. We found that qualitative and quantitative methods resulted in moderate to high concurrent validity when assessing the importance of place values in the study area. Convergent validity (spatial) was highly variable by place value, with stronger convergent validity found with mapped aesthetic, recreational fishing, tourism, biodiversity, and Aboriginal culture values, and weakest with existence, therapeutic, and commercial fishing values. Convergent validity was influenced by weak commensurate validity through the use of different geometric features (polygons versus points) for mapping values across a large study area. The utility of mixed methods for planning decision support in a convergent parallel design depends on demonstrating convergence in construct meaning, spatial location, and consistency in values in the sampling populations.}
}
@article{NIKITAKOS2018390,
title = {Autonomous Robotic Platform in Harm Environment Onboard of Ships},
journal = {IFAC-PapersOnLine},
volume = {51},
number = {30},
pages = {390-395},
year = {2018},
note = {18th IFAC Conference on Technology, Culture and International Stability TECIS 2018},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2018.11.337},
url = {https://www.sciencedirect.com/science/article/pii/S240589631833012X},
author = {Nikitas Nikitakos and George Tsaganos and Dimitrios Papachristos},
keywords = {Autonomous Robotics, Environment},
abstract = {Structural and machinery failures in the day-to-day ship operations may lead to major accidents, endangering crew onboard, posing a threat to the environment, damaging the ship itself and having a great impact in terms of business losses. Maintenance is a primary service to be performed in complex systems, especially those whose failures can compromise personnel and environmental safety, such as large ships on sailing. In this paper we present a proposed system for Harm Environment Onboard of Ships applications. It is low cost, open source software using robotic, embedded systems and IoT technologies. It offers protection of human resources in applications that are hazardous to human work.}
}
@article{JUN201869,
title = {Ten years of research change using Google Trends: From the perspective of big data utilizations and applications},
journal = {Technological Forecasting and Social Change},
volume = {130},
pages = {69-87},
year = {2018},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2017.11.009},
url = {https://www.sciencedirect.com/science/article/pii/S0040162517315536},
author = {Seung-Pyo Jun and Hyoung Sun Yoo and San Choi},
keywords = {Google Trends, Big data utilization, Big data application, Networks analysis, Author keyword, Science Journal Classification, Clustering},
abstract = {This study seeks to analyze the trends in research studies in the past decade which have utilized Google Trends, a new source of big data, to examine how the scope of research has expanded. Our purpose is to conduct a comprehensive and objective research into how the public use of Big Data from web searches has affected research, and furthermore, to discuss the implications of Google Trends in terms of Big Data utilization and application. To this end, we conducted a network analysis on 657 research papers that used Google Trends. We also identified the important nodes of the networks and reviewed the research directions of representative papers. The study reveals that Google Trends is used to analyze various variables in a wide range of areas, including IT, communications, medicine, health, business and economics. In addition, this study shows that research using Google Trends has increased dramatically in the last decade, and in the process, the focus of research has shifted to forecasting changes, whereas in the past the focus had been on merely describing and diagnosing research trends, such as surveillance and monitoring. This study also demonstrates that in recent years, there has been an expansion in analysis in linkage with other social Big Data sources, as researchers attempt to overcome the limitations of using only search information. Our study will provide various insights for researchers who utilize Google Trends as well as researchers who rely on various other sources of Big Data in their efforts to compare research trends and identify new areas for research.}
}
@article{BROWN201818,
title = {An evaluation of participatory mapping methods to assess urban park benefits},
journal = {Landscape and Urban Planning},
volume = {178},
pages = {18-31},
year = {2018},
issn = {0169-2046},
doi = {https://doi.org/10.1016/j.landurbplan.2018.05.018},
url = {https://www.sciencedirect.com/science/article/pii/S0169204618303815},
author = {Greg Brown and Jonathan Rhodes and Marie Dade},
keywords = {Urban parks, Physical activity, Benefits, Public participation GIS, PPGIS, Urban planning},
abstract = {Traditional urban park research has used self-reported surveys and activity logs to examine relationships between health benefits, park use, and park features. An alternative approach uses participating mapping methods. This study sought to validate and expand on previous participatory mapping research methods and findings and address spatial scaling by applying these methods to a large urban park system. Key challenges for spatial scaling included ambiguity in park classification and achieving representative sampling for larger and spatially-disbursed urban residents. We designed an internet-based public participation GIS (PPGIS) survey and used household and volunteer sampling to identify the type and locations of urban park benefits. Study participants (n = 816) identified locations of physical activities and other urban park benefits (psychological, social, and environmental) which were analyzed by park type. Consistent with previous suburb-scale research, we found significant associations between urban park type and different urban park benefits. Linear parks were significantly associated with higher intensity physical activities; natural parks were associated with environmental benefits; and community parks were associated with benefits from social interaction. Neighborhood parks emerged as significantly associated with psychological benefits. The diversity of park activities and benefits were positively correlated with park size. Distance analysis confirmed that physical benefits of parks were closest to participant domicile, while social and environmental benefits were more distant. These results validate previous suburb-scale findings despite greater variability in park types and sample populations. Future urban park research using participatory mapping would benefit from greater effort to obtain participation from under-represented populations that can induce nonresponse bias, and analyses to determine whether system-wide results can be disaggregated by suburb or neighborhood to address social inequities in urban park benefits.}
}
@article{BORDOGNA2012105,
title = {Geographic information retrieval: Modeling uncertainty of user's context},
journal = {Fuzzy Sets and Systems},
volume = {196},
pages = {105-124},
year = {2012},
note = {On Advances in Soft Computing Applied to Databases and Information Systems},
issn = {0165-0114},
doi = {https://doi.org/10.1016/j.fss.2011.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S0165011411001679},
author = {Gloria Bordogna and Giorgio Ghisalberti and Giuseppe Psaila},
keywords = {Geographic information retrieval, Fuzzy aggregation operators, Bipolar criteria evaluation, Geographic footprint, Context dependent spatial query, Soft constraint},
abstract = {Geographic information retrieval (GIR) is nowadays a hot research issue that involves the management of uncertainty and imprecision and the modeling of user preferences and context. Indexing the geographic content of documents implies dealing with the ambiguity, synonymy and homonymy of geographic names in texts. On the other side, the evaluation of queries specifying both content based conditions and spatial conditions on documents’ contents requires representing the vagueness and context dependency of spatial conditions and the personal user's preferences. The spatial condition can be specified linguistically in the query through vague terms such as “close to the North East of Milan’’, whose semantic depends on the user's context and perception of distance. Further, users may want to express queries in which the content condition and the spatial condition have a distinct preference and are combined with a distinct semantics. In this paper, we propose a geographic information retrieval model and a system implementing it that represents both the uncertainty in indexing the geographic documents’ content and the user's context and preferences in evaluating flexible spatial queries. It extracts the geographic content from documents’ text by applying heuristic knowledge coded by bipolar rules which evaluate positive hints and negative hints for the recognition of geographic names in text. Thus, it represents the geographic content of documents by fuzzy footprints, i.e., distinct locations on the earth associated with the text with a distinct degree of significance. Finally, the system allows evaluating two types of queries flexibly combining the content based condition with the spatial condition. The spatial condition is interpreted as the soft constraint “close’’ on the user's perceived distance between the documents’ footprint and query's footprint. For each retrieved document, two relevance scores are computed with respect to the two query conditions that are flexibly combined to generate an overall ranked list of documents. The user can choose the semantic for the combination that can be either an asymmetric “and possibly’’ aggregation between the mandatory content condition and the optional spatial condition, or a compensative “average’’ aggregation, defined as a linear combination of the two conditions; further, a relative preference between the conditions can be specified to achieve personalization and effectiveness. A prototypal geographic information retrieval system, named Geo-Finder, based on this model is described, and its evaluations are discussed.}
}
@incollection{CASTI2015119,
title = {Chapter 4 - Technology in Action: Participatory Cartographic Systems},
editor = {Emanuela Casti},
series = {Modern Cartography Series},
publisher = {Academic Press},
volume = {6},
pages = {119-164},
year = {2015},
booktitle = {Reflexive Cartography},
issn = {1363-0814},
doi = {https://doi.org/10.1016/B978-0-12-803509-2.00004-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128035092000045},
author = {Emanuela Casti},
keywords = {Geographic Information Technologies, GIS and WebGIS, Cartographer’s and interpreter’s role, Participatory mapping systems, Maps and democratization practices, Environmental protection in Africa, Counter Mapping},
abstract = {This chapter is meant as a preliminary introduction to experimental landscape cartography. It sets an exploratory path towards a chorographic metrics able to convey the social meaning of territory. I analyze the profound changes that have occurred in contemporary cartographic production, especially those investing the role of the interpreter and those related to the unprecedented social needs that maps are called upon to address. First I will consider the outcomes that Information Technology (IT) has had on mapping in promoting a wide range of new production sites and new professional profiles for cartographers. Then I will survey the social landscape that shows cartography’s involvement in the practices of democratization, both within governance policies or territorial planning and in terms of citizen access to data from public institutions. Finally, I will discuss the issue of participation in the collection of cartographic data and propose a model, pioneered in the field of environmental protection in Africa. I will present a methodology, called SIGAP (Geographic Information Systems for Protected Areas), which takes charge of the entire process of cartographic construction and produces participatory tools based on the use of geographic information systems (GIS). That will lead us to reflect on the semantic consequences of the availability of GIS tools online and, more specifically, to consider interactivity as a participatory potential for web-based cartography. This chapter will therefore provide a reflection on the importance of method for retrieving cartographic data; on the vital role of participation in the construction of maps; and on the potential WebGIS offer to promote such participation. These are essential conditions for rendering landscape in modes that pave the way to a chorography.∗}
}
@article{FERNANDEZCARAMES2016475,
title = {A real-time indoor localization approach integrated with a Geographic Information System (GIS)},
journal = {Robotics and Autonomous Systems},
volume = {75},
pages = {475-489},
year = {2016},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2015.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0921889015001736},
author = {Carlos Fernández-Caramés and F. Javier Serrano and Vidal Moreno and Belén Curto and J.F. Rodríguez-Aragón and Raúl Alves},
keywords = {Geographic Information System, Door detection, Autonomous robotics, Robot localization, Integral Image, Haar-like features},
abstract = {Nowadays, accurate maps from mostly anywhere in the world can be obtained for free, with the exception of indoor spaces. However, the evidence seems to suggest that in the next few years indoor maps will be more and more available for anyone. Thus, profiting from the idea of easily obtainable indoor maps, we present a novel approach for real-time mobile robot localization that focuses on spatial reasoning at a high abstraction level. In order to manage and query existing indoor spatial models, we rely on the power of Geographic Information Systems (GIS) and spatial databases. Moreover, to extract symbolic information from the environment, we have developed a door detection system that fuses 2D laser and vision data. We have integrated these two ideas into an extended Kalman filter localization framework. Our proposal has been implemented and tested through autonomous navigation missions in real-world scenarios. Extensive experimental results are provided, which show robustness and accuracy concerning both door detection and localization.}
}
@incollection{HEDGES201827,
title = {Chapter 3 - Processes and products: A typology of crowdsourcing},
editor = {Mark Hedges and Stuart Dunn},
booktitle = {Academic Crowdsourcing in the Humanities},
publisher = {Chandos Publishing},
pages = {27-49},
year = {2018},
isbn = {978-0-08-100941-3},
doi = {https://doi.org/10.1016/B978-0-08-100941-3.00003-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780081009413000036},
author = {Mark Hedges and Stuart Dunn},
keywords = {Assets, Definitions, Methodology, Output, Processes, Task, Typology},
abstract = {The key premise developed in Chapters 1 and 2Chapter 1Chapter 2 is that academic crowdsourcing forms a set of observable processes. In this chapter, we present a typology of these processes, with detailed explications of how and where they have been applied. First presented in Dunn and Hedges (2013), this typology identifies particular areas of activity and content for which academic crowdsourcing has proved significant. Putting this in the framework of a ‘methodological commons’, we describe four phases to the life cycle of academic crowdsourcing: asset, task type, process and output.}
}
@article{BROELEMANN2016195,
title = {Automatic understanding of sketch maps using context-aware classification},
journal = {Expert Systems with Applications},
volume = {45},
pages = {195-207},
year = {2016},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2015.09.037},
url = {https://www.sciencedirect.com/science/article/pii/S0957417415006661},
author = {Klaus Broelemann and Xiaoyi Jiang and Angela Schwering},
keywords = {Sketch map understanding, Context-aware classification, Relaxation labeling},
abstract = {Sketching is a natural and easy way for humans to express visual information in everyday life. Despite a number of approaches to understand online sketch maps, the automatic understanding of offline, hand-drawn sketch maps still poses a problem. This paper presents a new approach for novel sketch map understanding. To our knowledge, this is the first comprehensive work dealing with this task in an offline way. This paper presents a system for automatic understanding of sketch maps and the underlying algorithms for all steps. Major parts are a region-growing segmentation for sketch map objects, a classification for isolated objects, and a context-aware classification. The context-aware classification uses probabilistic relaxation labeling to integrate dependencies between objects into the recognition. We show how these algorithms can deal with the major problems of sketch map understanding, such as vagueness in interpretation. Our experiments demonstrate the importance of context-aware classification for sketch map understanding. In addition, a new database of annotated sketch maps was developed and is made publicly available. This can be used for training and evaluation of sketch map understanding algorithms.}
}
@article{DICKINSON2017179,
title = {Cultural ecosystem services: Characteristics, challenges and lessons for urban green space research},
journal = {Ecosystem Services},
volume = {25},
pages = {179-194},
year = {2017},
issn = {2212-0416},
doi = {https://doi.org/10.1016/j.ecoser.2017.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S2212041616305319},
author = {Dawn C. Dickinson and Richard J. Hobbs},
keywords = {Benefits, Definition, Measurement, Human, Wellbeing, Cities},
abstract = {City dwellers have fewer opportunities to connect with nature, with urban green space (UGS) often one of the few places where this can occur. Natural environments are known to contribute to human wellbeing, although to date research has largely focused on quantifiable benefits. The less tangible benefits obtained from ecosystems have commonly been referred to as ‘Cultural Ecosystem Services’ (CES). However, challenges persist around the definition and measurement of CES. A qualitative review of literature was conducted to identify key characteristics of CES, challenges to CES research, and lessons for the future of UGS research. The review found that CES have tended to be characterised by intangibility and incommensurability, when perhaps the most distinguishing features are the form and extent of human-environment co-production, and association between CES and held values. Despite ongoing challenges, researchers have applied a range of methods to capture and analyse CES, including non-economic and participatory/deliberative approaches. As urbanisation increases, it is important to understand how CES from UGS affect wellbeing. The review found that attention to date has mainly focused on identifying CES but scope exists to research the effects of UGS attributes, and how the socio-cultural diversity of cities might influence co-production of CES.}
}
@article{WHITTAKER2015358,
title = {A review of informal volunteerism in emergencies and disasters: Definition, opportunities and challenges},
journal = {International Journal of Disaster Risk Reduction},
volume = {13},
pages = {358-368},
year = {2015},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2015.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S2212420915300388},
author = {Joshua Whittaker and Blythe McLennan and John Handmer},
keywords = {Emergency, Disaster, Citizen action, Emergence, Informal volunteerism, Resilience},
abstract = {Despite highly specialised and capable emergency management systems, ordinary citizens are usually first on the scene in an emergency or disaster, and remain long after official services have ceased. Citizens often play vital roles in helping those affected to respond and recover, and can provide invaluable assistance to official agencies. However, in most developed countries, emergency and disaster management relies largely on a workforce of professionals and, to varying degrees, volunteers affiliated with official agencies. Those who work outside of such systems have tended to be viewed as a nuisance or liability, and their efforts are often undervalued. Given increasing disaster risk worldwide due to population growth, urban development and climate change, it is likely that ‘informal’ volunteers will provide much of the additional surge capacity required to respond to more frequent emergencies and disasters in the future. This paper considers the role of informal volunteers in emergency and disaster management. Definitions of volunteerism are reviewed and it is argued that there is an overemphasis on volunteering within, and for, state and formal organisations. We offer a broader definition of ‘informal volunteerism’ that recognises the many ways ordinary citizens volunteer their time, knowledge, skills and resources to help others in times of crisis. Two broad types of informal volunteerism are identified – emergent and extending – and the implications for emergency and disaster management are considered. Particular attention is given to increasing ‘digital volunteerism’ due to the greater accessibility of sophisticated but simple information and communication technologies. Culture and legal liability are identified as key barriers to greater participation of informal volunteers. We argue that more adaptive and inclusive models of emergency and disaster management are needed to harness the capacities and resilience that exist within and across communities.}
}
@incollection{2018441,
title = {Index},
editor = {Bo Huang},
booktitle = {Comprehensive Geographic Information Systems},
publisher = {Elsevier},
address = {Oxford},
pages = {441-461},
year = {2018},
isbn = {978-0-12-804793-4},
doi = {https://doi.org/10.1016/B978-0-12-804660-9.18001-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780128046609180015}
}
@article{WEBER201999,
title = {Are we ready for bushfire? Perceptions of residents, landowners and fire authorities on Lower Eyre Peninsula, South Australia},
journal = {Geoforum},
volume = {107},
pages = {99-112},
year = {2019},
issn = {0016-7185},
doi = {https://doi.org/10.1016/j.geoforum.2019.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0016718519302933},
author = {D. Weber and E. Moskwa and G.M. Robinson and D.K. Bardsley and J. Arnold and M.A. Davenport},
keywords = {Bushfires, Communities, Peri-urban fringe, Risk mitigation, Fire management, South Australia},
abstract = {Housing developments on the peri-urban fringe of Australian towns and cities create complexities for bushfire management due to the intermingling of natural, rural and urban spaces. To address the risk of bushfire, policies and practices have promoted and encouraged landowner responsibility for bushfire mitigation actions and behaviours. Using a postal survey, interviews and focus groups, we examine perceptions and actions regarding bushfire preparedness from the viewpoints of individual residents, landowners, and the local fire and environmental authorities on the Lower Eyre Peninsula of South Australia. Respondents living on larger sized allotments were more likely to perceive that their property was vulnerable to bushfire than those living on residential-sized allotments. Larger holdings tend to have more fire-susceptible vegetation than the smaller properties located in fringe suburbs, which seems to confer to those latter residents a sense of greater safety from bushfires. On the other hand, residents on larger blocks reported higher levels of bushfire management knowledge and expressed stronger connections to the place where they live, which influenced their willingness to work to mitigate bushfire risk. Importantly, there is a disconnection between such individual landholder preparedness for bushfire and that of the broader community. Individual actions often do not translate into collective responses, suggesting that a greater sense of shared responsibility will need to develop to enable effective mitigation of regional bushfire risk at a regional scale.}
}
@article{NULTY2016429,
title = {Social media and political communication in the 2014 elections to the European Parliament},
journal = {Electoral Studies},
volume = {44},
pages = {429-444},
year = {2016},
issn = {0261-3794},
doi = {https://doi.org/10.1016/j.electstud.2016.04.014},
url = {https://www.sciencedirect.com/science/article/pii/S0261379415300779},
author = {Paul Nulty and Yannis Theocharis and Sebastian Adrian Popa and Olivier Parnet and Kenneth Benoit},
keywords = {Electoral participation, Political communication, Social networks, European elections, Content analysis, Social media},
abstract = {Social media play an increasingly important part in the communication strategies of political campaigns by reflecting information about the policy preferences and opinions of political actors and their public followers. In addition, the content of the messages provides rich information about the political issues and the framing of those issues during elections, such as whether contested issues concern Europe or rather extend pre-existing national debates. In this study, we survey the European landscape of social media using tweets originating from and referring to political actors during the 2014 European Parliament election campaign. We describe the language and national distribution of the messages, the relative volume of different types of communications, and the factors that determine the adoption and use of social media by the candidates. We also analyze the dynamics of the volume and content of the communications over the duration of the campaign with reference to both the EU integration dimension of the debate and the prominence of the most visible list-leading candidates. Our findings indicate that the lead candidates and their televised debate had a prominent influence on the volume and content of communications, and that the content and emotional tone of communications more reflects preferences along the EU dimension of political contestation rather than classic national issues relating to left-right differences.}
}
@article{PECKHAM201724,
title = {Satellites and the New War on Infection: Tracking Ebola in West Africa},
journal = {Geoforum},
volume = {80},
pages = {24-38},
year = {2017},
issn = {0016-7185},
doi = {https://doi.org/10.1016/j.geoforum.2017.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S0016718517300015},
author = {Robert Peckham and Ria Sinha},
keywords = {Satellites, Epidemic intelligence, Ebola, West Africa, Digital divide, Vertical geopolitics},
abstract = {Satellite technologies are increasingly being deployed to manage infectious disease outbreaks. Although there is a substantive literature concerned with the geopolitics of space and the ethical issues raised by the use of remote sensing in warfare and counterinsurgency, little study has been made of the critical role played by satellites in public health crises. In this paper, we focus on the 2014–2015 Ebola virus disease (EVD) epidemic in West Africa, which saw the widespread use of public and commercial satellite-derived data, to investigate how overhead orbital and close-up viewpoints enabled by satellites are shaping attitudes to disease and determining responses to infectious threats. We argue that high-resolution satellite imagery is acting as a spur to a new spatio-temporal targeting of disease that parallels the ever more vertical dimension of contemporary warfare. At the same time, this new visualization of disease is promoting a broader ecological perspective on pathogen emergence. How can these divergent perspectives be reconciled? In addressing this question, we analyze the different uses to which satellite imagery has been put in tracking and mapping Ebola ‘hotspots’ across Guinea, Liberia, and Sierra Leone. We also consider the institutional contexts that have enabled the acquisition of this imagery. Given the rapid integration of space technologies in epidemiology and health logistics, there is now a need to examine how and with what consequences remote-sensing and communication technologies may be reconfiguring the practices and scope of global health.}
}
@article{KISILEVICH20131119,
title = {A GIS-based decision support system for hotel room rate estimation and temporal price prediction: The hotel brokers' context},
journal = {Decision Support Systems},
volume = {54},
number = {2},
pages = {1119-1133},
year = {2013},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2012.10.038},
url = {https://www.sciencedirect.com/science/article/pii/S0167923612003120},
author = {Slava Kisilevich and Daniel Keim and Lior Rokach},
keywords = {Hedonic methods, Hotels, Price prediction, Geographic Information Systems, Regression analysis, Data mining},
abstract = {The vastly increasing number of online hotel room bookings is not only intensifying the competition in the travel industry as a whole, but also prompts travel intermediates (i.e. e-companies that aggregate information about different travel products from different travel suppliers) into a fierce competition for the best prices of travel products, i.e. hotel rooms. An important factor that affects revenues is the ability to conclude profitable deals with different travel suppliers. However, the profitability of a contract not only depends on the communication skills of a contract manager. It significantly depends on the objective information obtained about a specific travel supplier and his/her products. While the contract manager usually has a broad knowledge of the travel business in general, collecting and processing specific information about travel suppliers is usually a time and cost expensive task. Our goal is to develop a tool that assists the travel intermediate to acquire the missing strategic information about individual hotels in order to leverage profitable deals. We present a GIS-based decision support system that can both, estimate objective hotel room rates using essential hotel and locational characteristics and predict temporal room rate prices. Information about objective hotel room rates allows for an objective comparison and provides the basis for a realistic computation of the contract's profitability. The temporal prediction of room rates can be used for monitoring past hotel room rates and for adjusting the price of the future contract. This paper makes three major contributions. First, we present a GIS-based decision support system, the first of its kind, for hotel brokers. Second, the DSS can be applied to virtually any part of the world, which makes it a very attractive business tool in real-life situations. Third, it integrates a widely used data mining framework that provides access to dozens of ready to run algorithms to be used by a domain expert and it offers the possibility of adding new algorithms once they are developed. The system has been designed and evaluated in close cooperation with a company that develops travel technology solutions, in particular inventory management and pricing solutions for many well-known websites and travel agencies around the world. This company has also provided us with real, large datasets to evaluate the system. We demonstrate the functionality of the DSS using the hotel data in the area of Barcelona, Spain. The results indicate the potential usefulness of the proposed system.}
}
@incollection{SEIBERT202193,
title = {Chapter 4 - Snow and ice in the hydrosphere},
editor = {Wilfried Haeberli and Colin Whiteman},
booktitle = {Snow and Ice-Related Hazards, Risks, and Disasters (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
pages = {93-135},
year = {2021},
isbn = {978-0-12-817129-5},
doi = {https://doi.org/10.1016/B978-0-12-817129-5.00010-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012817129500010X},
author = {Jan Seibert and Michal Jenicek and Matthias Huss and Tracy Ewen and Daniel Viviroli},
keywords = {Snow, Ice, Runoff, Seasonally frozen soils, Permafrost, Energy balance, Observations, Modeling, Climate change},
abstract = {In large areas of the world, runoff and other hydrological variables are controlled by the spatial and temporal variation of the 0°C isotherm, which is central for the temporal storage of precipitation as snow or ice. This storage is of crucial importance for the seasonal distribution of snow and ice melt, a major component of the movement of water in the global water cycle. This chapter provides an introduction to the role of snow and ice in the hydrosphere by discussing topics including snowpack characteristics, snow observation approaches, the energy balance of snow-covered areas, and modeling of snowmelt. Furthermore, the role of glaciers and glacial mass balances, including modeling glacier discharge, is discussed. An overview of the hydrology of snow- and ice-covered catchments is given, and the influence of snow, glaciers, river ice, seasonally frozen soils, and permafrost on discharge is discussed. Finally, the impacts of climate change on snow and ice are discussed.}
}
@incollection{DAY201433,
title = {Chapter 3.1 - Preparing for Fieldwork},
editor = {Mary J. Thornbush and Casey D. Allen and Faith A. Fitzpatrick},
series = {Developments in Earth Surface Processes},
publisher = {Elsevier},
volume = {18},
pages = {33-63},
year = {2014},
issn = {0928-2025},
doi = {https://doi.org/10.1016/B978-0-444-63402-3.00004-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780444634023000042},
author = {Mick Day},
keywords = {fieldwork, preparation, professional goals, practical constraints, flexibility, time, personnel, finances, impacts},
abstract = {Preparation is a critical and repetitive component of successful field research in geomorphology. Rigorous professional academic objectives and plans must be reconciled with practical and logistic constraints, in a way that resources (time, effort, money) are used to the best effect. Fieldwork has many potential components, of which the acquisition of field data for hypothesis testing is pivotal. Key to preparation is the recognition that things can and will go awry, necessitating prior consideration of “what if?,” and the formulation of alternative, fallback plans, and “safety nets.” Temporal and spatial scales are fundamental considerations, and proper preparation should result in fieldwork projects that are both meaningful and manageable as components of broader geomorphic research. Important considerations include those revolving around personnel selection and management, equipment needs, institutional and personal support systems, safety, health and fitness, emergency planning, finances, authorization, transportation, accommodation, and prior understanding of and adjustment to both the physical and human environments in which fieldwork occurs.}
}
@article{NEUTENS2010561,
title = {Arranging place and time: A GIS toolkit to assess person-based accessibility of urban opportunities},
journal = {Applied Geography},
volume = {30},
number = {4},
pages = {561-575},
year = {2010},
note = {Climate Change and Applied Geography – Place, Policy, and Practice},
issn = {0143-6228},
doi = {https://doi.org/10.1016/j.apgeog.2010.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S0143622810000585},
author = {Tijs Neutens and Mathias Versichele and Tim Schwanen},
keywords = {Time geography, Accessibility, Geographical information science},
abstract = {In this paper a GIS toolkit (http://cartogis.ugent.be/sta_toolkit) is described that is able to assess the accessibility of urban opportunities to one or multiple persons. Based on information about the transportation system, urban opportunities and individual activity schedules, the toolkit provides a dynamic and animated view of the activity locations that are accessible to a person or group during the course of the day. By developing the toolkit we seek to contribute not only to the literature about space-time accessibility analysis and activity-based travel demand analysis but also to the dissemination of time geographical concepts to wider audiences. To achieve the latter, we have implemented the toolkit as a stand-alone application that is independent of commercial software and the platform used. Query results can easily be exported to Google™ Earth/Maps as well as conventional GIS software. As an illustrative example, a representative day-to-day rendezvous scenario was set up to demonstrate how meeting possibilities are shaped by various individual spatial and temporal constraints.}
}
@article{ALAMDAR2017475,
title = {Understanding the provision of multi-agency sensor information in disaster management: A case study on the Australian state of Victoria},
journal = {International Journal of Disaster Risk Reduction},
volume = {22},
pages = {475-493},
year = {2017},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2016.10.008},
url = {https://www.sciencedirect.com/science/article/pii/S2212420916302023},
author = {Farzad Alamdar and Mohsen Kalantari and Abbas Rajabifard},
keywords = {Multi-agency emergency management, Flood disaster management, Sensor information, Internet of Things (IoT), In situ sensing, OGC Sensor Web Enablement (SWE), Sensor network},
abstract = {Excitement about the potential usage of sensor data sourcing to provide near real-time information has spread to the emergency management sector. Despite the advantages that shared sensor-derived situational awareness may provide, research has been limited on the actual utilization of multi-vendor sensor data in disaster management. In consideration of this shortcoming, an empirical case study is conducted in the Australian state of Victoria to understand the current practices and requirements for access, exchange, and usage of multi-agency sensor data amongst participants in flood disaster organizations. First-hand knowledge of sensor data producers and disaster decision-makers is used, disclosing serious technical barriers to interoperable access to the highly disparate organizational sensor data. The findings also uncover the mechanisms in use for integrating multi-agency sensory information in disaster management, revealing the capabilities required of stakeholders to derive disaster information from raw sensor feeds.}
}
@article{WALLER20144,
title = {Putting spatial statistics (back) on the map},
journal = {Spatial Statistics},
volume = {9},
pages = {4-19},
year = {2014},
note = {Revealing Intricacies in Spatial and Spatio-Temporal Data: Papers from the Spatial Statistics 2013 Conference},
issn = {2211-6753},
doi = {https://doi.org/10.1016/j.spasta.2014.03.007},
url = {https://www.sciencedirect.com/science/article/pii/S2211675314000207},
author = {Lance A. Waller},
keywords = {Spatial thinking, Statistical thinking, Spatial statistics},
abstract = {The literature in Geographical Information Science and Statistical Science often contains calls for analysts to “think spatially” and to “think statistically”, respectively, in order to gain better insight into proposed hypotheses. A central element of these calls involves the development of a spatial intuition or a statistical intuition, i.e., conceptual ways of framing questions, incorporating available data, calculating quantitative summaries, interpreting outcomes, and providing empirical answers from either a spatial or a statistical perspective. In this paper, I draw on past experience to identify and illustrate the potential for “spatial statistical thinking”, that is, the development of a spatial statistical intuition. Several examples illustrate the potential for a more explicit development of such intuition drawing simultaneously from both spatial analysis and statistics. As a step in this direction, I stress the importance of maintaining a spatial conceptual framework in the application and interpretation of spatial statistical methods, i.e., the importance of spatial interpretation of spatial statistics.}
}
@incollection{2020319,
title = {Index},
editor = {Audrey Kobayashi},
booktitle = {International Encyclopedia of Human Geography (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {319-407},
year = {2020},
isbn = {978-0-08-102296-2},
doi = {https://doi.org/10.1016/B978-0-08-102295-5.18001-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780081022955180011}
}
@article{HU2019157,
title = {Framework for prioritizing geospatial data processing tasks during extreme weather events},
journal = {Advanced Engineering Informatics},
volume = {39},
pages = {157-169},
year = {2019},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2018.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S1474034618301010},
author = {Xuan Hu and Jie Gong},
keywords = {Disaster response, Decision support, Data processing prioritization, Data envelop analysis, Group decision processes},
abstract = {In recent years, advanced geospatial technologies have been playing an increasingly important role in supporting critical decision makings in disaster response. One rising challenge to effectively use the growing volume of geospatial data sets is to rapidly process the data and to extract useful information. Unprocessed data are intangible and non-consumable, and often create the so-called “data-rich-but-information-poor” situation. To address this issue, this study proposed a Data Envelopment Analysis (DEA) based information salience framework to prioritize the sequence of the information processing tasks. The proposed model integrates the DEA efficiency score with a linguistic group decision process. For the input variables, computational complexity and intensity are selected to measure the difficulty in information processing. For the outputs, the performance of each processing tasks is evaluated based on the experts’ judgment on how the processing tasks satisfy the needs of decision makers. These needs are characterized by four classic disaster functions. A unique element of our proposed framework is that cone constraints are added to the DEA model based on the experts’ evaluation of the importance of the four disaster functions to model the dynamic information need. The proposed model was validated with a Hurricane Sandy based case study. The results indicate that the proposed framework is capable of prioritizing geospatial data processing tasks in a systematic manner and accelerating information extraction from disaster related geospatial data sets.}
}
@article{ZHANG2018684,
title = {Geospatial sensor web: A cyber-physical infrastructure for geoscience research and application},
journal = {Earth-Science Reviews},
volume = {185},
pages = {684-703},
year = {2018},
issn = {0012-8252},
doi = {https://doi.org/10.1016/j.earscirev.2018.07.006},
url = {https://www.sciencedirect.com/science/article/pii/S0012825217305044},
author = {Xiang Zhang and Nengcheng Chen and Zeqiang Chen and Lixin Wu and Xia Li and Liangpei Zhang and Liping Di and Jianya Gong and Deren Li},
keywords = {Collaborative observation, Focusing service, Geoscience, Geospatial, Infrastructure, Integrated management, Scalable processing, Sensor web},
abstract = {In the last half-century, geoscience research has advanced due to multidisciplinary technologies, among which Information and Communication Technology (ICT) has played a vital role. However, scientifically organizing these ICTs toward improving geoscience measurements, data processing, and information services has encountered tremendous challenges. This paper reviews a profound revolution in geoscience that has resulted from the Geospatial Sensor Web (GSW), serving as a new cyber-physical spatio-temporal information infrastructure for geoscience on the World Wide Web (WWW). In contrast to previous experiment-based and sensor-based paradigms, the GSW-based paradigm is able to accomplish the following: (1) achieve integrated and sharable management of diverse sensing resources, (2) obtain real-time or near real-time and spatiotemporal continuous data, (3) conduct interoperable and online geoscience data processing and analysis, and (4) provide focusing services with web-based geoscience information and knowledge. As a benefit of the GSW, increasingly more geoscience disciplines are enjoying the value of real-time data, multi-source monitoring, online processing, and intelligence services. This paper reviews the evolution of geoscience research paradigm to demonstrate the scientific background of GSW. Then, we elaborates on four key methods provided by GSW, namely, integrated management, collaborative observation, scalable processing and fusion, and focusing service web capacity. Furthermore, current GSW prototypes and applications for environmental, hydrological, and natural disaster analysis are also reviewed. Moreover, four challenges to the future GSW in geoscience research are identified and analyzed, including integration with the Model Web initiative for sophisticated geo-processing, integration with humans for pervasive sensing, integration with Internet of Things (IoT) to achieve high-quality performance and data mining, and integration with Artificial Intelligence (AI) to provide smart geoservices. We have concluded that GSW has become an indispensable cyber-physical infrastructure, and will play a greater role in geoscience research and application.}
}
@article{LEGG2012184,
title = {Reading Matthew G. Hannah’s Dark Territory in the Information Age: Learning from the West German Census Controversies of the 1980s},
journal = {Political Geography},
volume = {31},
number = {3},
pages = {184-193},
year = {2012},
issn = {0962-6298},
doi = {https://doi.org/10.1016/j.polgeo.2012.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0962629812000054},
author = {Stephen Legg and Patricia Ehrkamp and Jeremy W. Crampton and Bernd Belina and Neil Smith and Matthew G. Hannah}
}
@article{BURNS201451,
title = {Moments of closure in the knowledge politics of digital humanitarianism},
journal = {Geoforum},
volume = {53},
pages = {51-62},
year = {2014},
issn = {0016-7185},
doi = {https://doi.org/10.1016/j.geoforum.2014.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S0016718514000323},
author = {Ryan Burns},
keywords = {Digital humanitarianism, Knowledge politics, Geoweb, Critical technology studies},
abstract = {Geographers interested in the social and political implications of the geoweb have recently turned their attention to its attendant “knowledge politics”. Such work looks at the processes and discrete moments in development that led to certain knowledges being represented and other knowledges remaining invisible. In this paper I build on these conversations by exploring the knowledge politics of digital humanitarianism. Digital humanitarianism, a technological corollary to the geoweb, is the set of social and institutional networks, technologies, and practices that enable large numbers of remote and on-the-ground individuals to collaborate on humanitarian projects. Specifically, in this paper I offer 4 “moments of closure” when knowledge politics have been negotiated, enacted, and made durable in digital humanitarianism. These moments of closure constellate around the themes of inclusion, categorization, accuracy, and visibility. I then consider the implications of these moments for the kinds of epistemologies digital humanitarianism espouses, and how knowledges come to be represented. I argue that these knowledge politics – the struggles for legitimacy and means of representation – are fluid and contested, yet become more stable when implemented through technology. Through these processes digital humanitarianism, and by extension the geoweb, embodies the social relations that first produced the debates around knowledge representation.}
}
@article{AALAMI2017400,
title = {Fair Dynamic Resource Allocation in Transit-based Evacuation Planning},
journal = {Transportation Research Procedia},
volume = {23},
pages = {400-419},
year = {2017},
note = {Papers Selected for the 22nd International Symposium on Transportation and Traffic Theory Chicago, Illinois, USA, 24-26 July, 2017.},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2017.05.023},
url = {https://www.sciencedirect.com/science/article/pii/S2352146517303010},
author = {Soheila Aalami and Lina Kattan},
keywords = {Emergency Evacuation, Resource Allocation, Fairness, Optimization, Distributed Algorithms},
abstract = {Abstract:
Resource allocation in transit-based emergency evacuation is studied in this paper. The goal is to find a method for allocation of resources to communities in an evacuation process which is (1) fair, (2) reasonably efficient, and (3) able to dynamically adapt to the changes to the emergency situation. Four variations of the resource allocation problem, namely maximum rate, minimum clearance time, maximum social welfare, and proportional fair resource allocation, are modeled and compared. It is shown that the optimal answer to each problem can be found efficiently. Additionally, a distributed and dynamic algorithm based on the Lagrangian dual approach, called PFD2A, is developed to find the proportional fair allocation of resources. Numerical results for a sample scenario are presented.}
}
@article{KAISER2013708,
title = {Enabling real-time city sensing with kernel stream oracles and MapReduce},
journal = {Pervasive and Mobile Computing},
volume = {9},
number = {5},
pages = {708-721},
year = {2013},
note = {Special issue on Pervasive Urban Applications},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2012.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1574119212001381},
author = {Christian Kaiser and Alexei Pozdnoukhov},
keywords = {Sensor networks, Machine learning, Kernel methods, Spatial statistics, Smart cities},
abstract = {An algorithmic architecture for kernel-based modelling of data streams from city sensing infrastructures is introduced. It is both applicable for pre-installed, moving and extemporaneous sensors, including the “citizen-as-a-sensor” view on user-generated data. The approach is centred around a kernel dictionary implementing a general hypothesis space which is updated incrementally, accounting for memory and processing capacity limitations. It is general for both kernel-based classification and regression. An extension to area-to-point modelling is introduced to account for the data aggregated over a spatial region. A distributed implementation realised under the Map-Reduce framework is presented to train an ensemble of sequential kernel learners.}
}
@article{SIEBER2015308,
title = {Civic open data at a crossroads: Dominant models and current challenges},
journal = {Government Information Quarterly},
volume = {32},
number = {3},
pages = {308-315},
year = {2015},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2015.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X15000611},
author = {Renee E. Sieber and Peter A. Johnson},
keywords = {Open data, Open government, Data sharing, Participatory, Data provision},
abstract = {As open data becomes more widely provided by government, it is important to ask questions about the future possibilities and forms that government open data may take. We present four models of open data as they relate to changing relations between citizens and government. These models include; a status quo ‘data over the wall’ form of government data publishing, a form of ‘code exchange’, with government acting as an open data activist, open data as a civic issue tracker, and participatory open data. These models represent multiple end points that can be currently viewed from the unfolding landscape of government open data. We position open data at a crossroads, with significant concerns of the conflicting motivations driving open data, the shifting role of government as a service provider, and the fragile nature of open data within the government space. We emphasize that the future of open data will be driven by the negotiation of the ethical-economic tension that exists between provisioning governments, citizens, and private sector data users.}
}
@article{CRUTCHER2009523,
title = {Placemarks and waterlines: Racialized cyberscapes in post-Katrina Google Earth},
journal = {Geoforum},
volume = {40},
number = {4},
pages = {523-534},
year = {2009},
note = {Themed Issue: The ‘view from nowhere’? Spatial politics and cultural significance of high-resolution satellite imagery},
issn = {0016-7185},
doi = {https://doi.org/10.1016/j.geoforum.2009.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S0016718509000049},
author = {Michael Crutcher and Matthew Zook},
keywords = {New orleans, Hurricane katrina, Internet, Google, Racialized landscapes, Cyberscape, Digiplace},
abstract = {Google Earth was released a few months prior to Hurricane Katrina and became an important tool in distributing information about the damage occurring in New Orleans, albeit not to all parts of society. While Google Earth did not create the economic and racial divides present in society, its use in the post-Katrina context reflect this gulf and have arguably reinforced and recreated it online. This paper has three main objectives. The first is to provide a clear empirical case study of how race remains relevant to the way people use (or do not use) the internet and internet based services. The second is highlighting the power of new online and interactive mapping technologies and demonstrating how these technologies are differentially adopted. The third and final objective is illustrating how any divide in accessing digital technology is not simply a one time event but a constantly moving target as new devices, software and cultural practices emerge. Thus, in addition to highlighting the racial inequalities in US society in general, Hurricane Katrina provides an important window on the way in which race remains a key factor in the access and use of emerging digital technologies.}
}
@article{WOLF2015112,
title = {The use of public participation GIS (PPGIS) for park visitor management: A case study of mountain biking},
journal = {Tourism Management},
volume = {51},
pages = {112-130},
year = {2015},
issn = {0261-5177},
doi = {https://doi.org/10.1016/j.tourman.2015.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0261517715000989},
author = {Isabelle D. Wolf and Teresa Wohlfart and Greg Brown and Abraham {Bartolomé Lasa}},
keywords = {Public participation GIS, Visitor activity management, Spatial distributions, Protected areas, Mountain biking},
abstract = {Spatially-explicit participatory planning is a relatively new approach for managing visitors to protected areas. In this study we used public participation geographic information systems (PPGIS) mapping and global positioning system (GPS) tracking to monitor mountain bikers frequenting national parks for tourism and recreation in Northern Sydney, Australia. PPGIS was implemented using both an internet application and with hardcopy maps in the field. Our research addressed two fundamental questions for park planning: (1) What is the spatial distribution of visitor activities and location-specific reasons for riding; and (2) What location-specific actions are needed to improve riding experiences? The spatial distributions of riding activities generated in PPGIS showed strong correlation with the GPS tracking results, with riding locations being related to the reasons for track selection. Riders proposed a broad range of management actions to improve riding experiences. PPGIS mapping provides a cost-effective approach to facilitate spatial decision making, allowing park agencies to prioritise future visitor management actions. We discuss the strengths and limitations of these research methods.}
}
@article{LUSCHER201318,
title = {Exploiting empirical knowledge for automatic delineation of city centres from large-scale topographic databases},
journal = {Computers, Environment and Urban Systems},
volume = {37},
pages = {18-34},
year = {2013},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2012.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0198971512000609},
author = {Patrick Lüscher and Robert Weibel},
keywords = {Pattern recognition, Topographic database, Semantic modelling, Urban structure, City centre},
abstract = {Current topographic databases rarely represent higher order geographic phenomena, such as city centres. However, such concepts are often referred to by humans and used in various forms of spatial analysis. Hence, the value and usability of topographic databases can greatly be improved by methods that automatically create such higher order phenomena through cartographic pattern recognition techniques, departing from the very detailed, geometry-oriented representations of topographic databases. As many higher order phenomena are only vaguely defined, this paper develops and evaluates a methodology to acquire definitional knowledge about geographic phenomena by participant experiments and use this knowledge to drive the cartographic pattern recognition process. The method is applied to acquire knowledge about British city centres and delineate referents of city centre from topographic data. City centres produced for ten British cities are compared to areas derived from alternative sources. F1-scores between 0.45 and 0.88 are achieved, suggesting that the delineation produced plausible city centre areas. The benefits of our work are better (and user-driven) descriptions of complex geographic phenomena that can form the basis for accurately enriching topographic databases with additional semantics, thus yielding added value for the data producer and the end user.}
}
@article{MERTES2015331,
title = {Detecting change in urban areas at continental scales with MODIS data},
journal = {Remote Sensing of Environment},
volume = {158},
pages = {331-347},
year = {2015},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2014.09.023},
url = {https://www.sciencedirect.com/science/article/pii/S003442571400368X},
author = {C.M. Mertes and A. Schneider and D. Sulla-Menashe and A.J. Tatem and B. Tan},
keywords = {Urban areas, Urbanization, Cities, Land cover, Change detection, Classification, Machine learning, Decision trees, Data fusion, Decision fusion},
abstract = {Urbanization is one of the most important components of global environmental change, yet most of what we know about urban areas is at the local scale. Remote sensing of urban expansion across large areas provides information on the spatial and temporal patterns of growth that are essential for understanding differences in socioeconomic and political factors that spur different forms of development, as well the social, environmental, and climatic impacts that result. However, mapping urban expansion globally is challenging: urban areas have a small footprint compared to other land cover types, their features are small, they are heterogeneous in both material composition and configuration, and the form and rates of new development are often highly variable across locations. Here we demonstrate a methodology for monitoring urban land expansion at continental to global scales using Moderate Resolution Imaging Spectroradiometer (MODIS) data. The new method focuses on resolving the spectral and temporal ambiguities between urban/non-urban land and stable/changed areas by: (1) spatially constraining the study extent to known locations of urban land; (2) integrating multi-temporal data from multiple satellite data sources to classify c. 2010 urban extent; and (3) mapping newly built areas (2000–2010) within the 2010 urban land extent using a multi-temporal composite change detection approach based on MODIS 250m annual maximum enhanced vegetation index (EVI). We test the method in 15 countries in East–Southeast Asia experiencing different rates and manifestations of urban expansion. A two-tiered accuracy assessment shows that the approach characterizes urban change across a variety of socioeconomic/political and ecological/climatic conditions with good accuracy (70–91% overall accuracy by country, 69–89% by biome). The 250m EVI data not only improve the classification results, but are capable of distinguishing between change and no-change areas in urban areas. Over 80% of the error in the change detection can be related to definitional issues or error propagation, rather than algorithm error. As such, these methods hold great potential for routine monitoring of urban change, as well as for providing a consistent and up-to-date dataset on urban extent and expansion for a rapidly evolving region.}
}
@article{MCCOY201774,
title = {Geospatial Big Data and archaeology: Prospects and problems too great to ignore},
journal = {Journal of Archaeological Science},
volume = {84},
pages = {74-94},
year = {2017},
note = {Archaeological GIS Today: Persistent Challenges, Pushing Old Boundaries, and Exploring New Horizons},
issn = {0305-4403},
doi = {https://doi.org/10.1016/j.jas.2017.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S0305440317300821},
author = {Mark D. McCoy},
keywords = {Geospatial, Big Data, Spatial technology, Cyberinfrastructure, Data science},
abstract = {As spatial technology has evolved and become integrated in to archaeology, we face a new set of challenges posed by the sheer size and complexity of data we use and produce. In this paper I discuss the prospects and problems of Geospatial Big Data (GBD) – broadly defined as data sets with locational information that exceed the capacity of widely available hardware, software, and/or human resources. While the datasets we create today remain within available resources, we nonetheless face the same challenges as many other fields that use and create GBD, especially in apprehensions over data quality and privacy. After reviewing the kinds of archaeological geospatial data currently available I discuss the near future of GBD in writing culture histories, making decisions, and visualizing the past. I use a case study from New Zealand to argue for the value of taking a data quantity-in-use approach to GBD and requiring applications of GBD in archaeology be regularly accompanied by a Standalone Quality Report.}
}
@article{AKBARI201752,
title = {Multi-vehicle prize collecting arc routing for connectivity problem},
journal = {Computers & Operations Research},
volume = {82},
pages = {52-68},
year = {2017},
issn = {0305-0548},
doi = {https://doi.org/10.1016/j.cor.2017.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S0305054817300072},
author = {Vahid Akbari and F. Sibel Salman},
keywords = {Arc routing, Prize collecting, Network connectivity, Road clearance, Disaster response, Mixed integer programming, Matheuristic},
abstract = {For effective disaster response, roads should be cleared or repaired to provide accessibility and relief services to the affected people in shortest time. We study an arc routing problem that aims to regain the connectivity of the road network components by clearing a subset of the blocked roads. In this problem, we maximize the total prize gained by reconnecting disconnected network components within a specified time limit. The solution should determine the coordinated routes of each work troop starting at a depot node such that none of the closed roads can be traversed unless their unblocking/clearing procedure is finished. We develop an exact Mixed Integer Program (MIP) and a matheuristic method. The matheuristic solves single vehicle problems sequentially with updated prizes. To obtain an upper bound, we first relax the timing elements in the exact formulation and then solve its relaxed MIP, which decomposes into single vehicle problems, by Lagrangian Relaxation. We show the effectiveness of the proposed methods computationally on both random Euclidean and Istanbul road network data generated with respect to predicted earthquake scenarios.}
}
@article{SCHULTZ201380,
title = {InSpace3D: A Middleware for Built Environment Data Access and Analytics},
journal = {Procedia Computer Science},
volume = {18},
pages = {80-89},
year = {2013},
note = {2013 International Conference on Computational Science},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2013.05.171},
url = {https://www.sciencedirect.com/science/article/pii/S1877050913003141},
author = {Carl Schultz and Mehul Bhatt},
keywords = {Architecture, Spatial Analysis, Artificial Intelligence, Building Information Model},
abstract = {Standardisation, archiving, and digital access of spatial data pertaining to built-up environments is an area acquiring increasing attention amongst several interest groups: policy makers, designers and planners, civil engineers, infrastructure management and public service personnel, building users. Initiatives such as the Building Information Model (BIM), Industry Founda- tion Classes (IFC), and CityGML are creating the information-theoretic backbone that guides the crucial aspects of quality, exchange, and interoperability of spatial data at the environmental and urban scale. However, due to the inherent scale, com- plexity, and detailed geometric character of building information data, extracting useful semantic and qualitative knowledge for accomplishing high-level analytical tasks is still an extremely complex and error prone process involving data intensive computing. We propose a uniform spatial data access middleware that can provide a combination of high-level, multi-modal, semantic, and quantitative-qualitative spatial data access and analytical capability. We present the core computational capabil- ities for the proposed middleware and present an overview of the high-level spatial model and its compliance with the industry standard IFC. A key theoretical contribution is a framework for investigating the computational complexity of deriving spatial artefacts within the context of building informatics. Additionally, we empirically investigate the feasibility and practicality of the derivation of spatial artefacts by conducting experiments on seven industry-scale IFC models. The experiment results show that, despite having non-linear polynomial increase with respect to time, deriving spatial artefacts is practical with large designs.}
}
@article{ZHANG201963,
title = {Geostatistical characterization of local accuracies in remotely sensed land cover change categorization with complexly configured reference samples},
journal = {Remote Sensing of Environment},
volume = {223},
pages = {63-81},
year = {2019},
issn = {0034-4257},
doi = {https://doi.org/10.1016/j.rse.2019.01.008},
url = {https://www.sciencedirect.com/science/article/pii/S0034425719300082},
author = {Jingxiong Zhang and Wangle Zhang and Yingying Mei and Wenjing Yang},
keywords = {Local accuracy, Land cover change, Non-collocated, Reference sample data, Sampling, Class occurrence pattern indices, Cross-correlation, Pseudo cross-variograms},
abstract = {Accuracy is an integral component in consumption of land cover and change information. Accuracy characterization in change categorization is more complicated than that in single-date classifications, especially when pursued at a local or per-pixel basis. In this paper, reference sample data consisting of reference class labels at sample locations are referred to as (model) training and validation sample data, respectively, when they are used for building and testing predictive models of local accuracy. They are preferably collocated to verify land cover and change types at the same locations across multiple single-date classifications. With collocated training data, methods devised for local accuracy mapping were usually implemented as direct extensions to those designed for accuracy predictions in single-date land cover maps, given that both response and explanatory variables are defined properly based on change maps. However, alternative methods are required when collocated training sample data are unavailable or sparse but non-collocated data collected at sample units not aligned across time exist or can be made available more conveniently and flexibly. This is typically the case for change-classification accuracy analyses, whereby prior sampling design and sample data may not remain informative in time but can be made adaptive by restructuring and augmentation to better represent strata of transitions as well as persistence. Such adaptability leads to great cost-saving in sampling than undertaking collocated sampling anew each time performing or revising accuracy mapping for a specific change analysis over a particular period. With a coherent review of related research, this paper proposes a geostatistical method for predictive mapping of local accuracies in any land-cover change maps created properly through adaptive use of complexly configured training sample data. This method works on a functional relation between accuracies in change-categorization and single-date classifications whereby temporal correlation (cross-correlation) between bi-temporal classification correctness is accommodated. In this cross-correlation-adjusted product method (named PXCOV), quantification of single-date classification accuracies is based on logistic regression. Cross-correlation is estimated via cross-validation cokriging through exploiting a useful relation between traditional and pseudo cross-variograms in the absence of collocated sample data or calculated more easily on the basis of collocated sample data if available. Studies were undertaken to test this method and compare it with direct logistic-regression-kriging (named LogRK direct), its simpler version, direct logistic regression without kriging (named LogR direct), and the baseline product method (named Product, being a simpler option of PXCOV without accounting for cross-correlation), using GlobeLand30 2000 and 2010 land cover at five sites in China. For each site, eleven training samples of equal sizes but differing configurations and one independent validation sample were collected. Logistic regression was performed on map class occurrence pattern indices quantified in size-optimized moving windows for mapping local accuracies in single-date classifications (as necessary intermediate steps in Product and PXCOV) and bi-temporal change-categorization (LogR direct and LogRK direct). In LogRK direct, geostatistical modeling and kriging were based on standardized residuals after logistic regression (based on change maps directly). In PXCOV, cross-correlation between single-date classification correctness was estimated and accounted for properly, with their non-stationarity in change vs. no-change strata of sample pixels accommodated, after estimating aforementioned single-date local accuracies. Statistical testing of relative performances of alternative methods was undertaken based on validation samples for individual study sites. It was confirmed that the proposed method PXCOV is more accurate than LogR direct and LogRK direct when there are relatively few collocated sample pixels (i.e., the typical scenarios justifying use of PXCOV). PXCOV is generally more accurate than Product and should be pursued when enough collocated data are available for estimating cross-correlation, although Product is sometimes adequate for practical purposes. LogR direct is recommended over LogRK direct because collocated sample data are often sparse due to low sampling intensities as in large-area applications. Therefore, as a method complementing LogR direct and similar methods, PXCOV facilitates adaptive use of training sample data of complex configurations for increased accuracy and efficiency in predictive mapping of local change-categorization accuracies.}
}